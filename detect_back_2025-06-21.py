import numpy as np
import pcammls
from pcammls import *
import cv2
import open3d
from skimage.morphology import skeletonize
from scipy.ndimage import label


class PythonPercipioDeviceEvent(pcammls.DeviceEvent):
    Offline = False

    def __init__(self):
        pcammls.DeviceEvent.__init__(self)

    def run(self, handle, eventID):
        if eventID == TY_EVENT_DEVICE_OFFLINE:
            print('=== Event Callback: Device Offline!')
            self.Offline = True
        return 0

    def IsOffline(self):
        return self.Offline


def extract_nearest_surface_mask(roi_p3d_aligned, depth_margin):
    """
    ä» ROI ç‚¹äº‘ä¸­æå–æœ€æµ…è¡¨é¢çš„ maskï¼ˆåŸºäº Z å€¼å±‚æå–ï¼‰

    å‚æ•°:
        roi_p3d_aligned: np.ndarray, å½¢çŠ¶ (H, W, 3)ï¼Œç‚¹äº‘æ•°æ®
        depth_margin: å®¹å·®èŒƒå›´ï¼ˆå•ä½: mmï¼‰ï¼Œç”¨äºæ„é€ æ·±åº¦å±‚åšåº¦

    è¿”å›:
        surface_mask: np.ndarray, å½¢çŠ¶ (H, W)ï¼Œuint8 ç±»å‹äºŒå€¼æ©ç ï¼Œ255è¡¨ç¤ºæœ€æµ…å±‚åŒºåŸŸ
        z_min_val: æœ€å°æ·±åº¦å€¼ï¼ˆè·ç¦»æœ€è¿‘çš„ mm å€¼ï¼‰
    """

    # 1. æå– Z å€¼å›¾
    z_img = roi_p3d_aligned[:, :, 2].copy()
    z_img[z_img <= 0] = 0  # è¿‡æ»¤æ— æ•ˆå€¼

    valid_mask = z_img > 0
    if not np.any(valid_mask):
        print("æ— æœ‰æ•ˆæ·±åº¦å€¼")
        return None, None

    z_min_val = np.min(z_img[valid_mask])
    print("\tæœ€å°æ·±åº¦å€¼:{}mm".format(z_min_val))

    # 2. åˆ›å»º maskï¼Œæå– z_min é™„è¿‘çš„ä¸€å±‚
    lower = z_min_val
    upper = z_min_val + depth_margin
    surface_mask = ((z_img >= lower) & (z_img <= upper)).astype(np.uint8) * 255  # äºŒå€¼æ©ç 

    return surface_mask, z_min_val


def extract_outer_inner_contours(surface_mask, simplify_epsilon=4):
    """
    ä»è¡¨é¢ mask ä¸­æå–å¤–è½®å»“å’Œå†…è½®å»“ï¼Œå¹¶è¿›è¡Œå¤šè¾¹å½¢æ‹Ÿåˆ

    å‚æ•°:
        surface_mask: np.ndarray, äºŒå€¼å›¾åƒ (H, W)ï¼Œ255 è¡¨ç¤ºç›®æ ‡åŒºåŸŸ
        simplify_epsilon: æ‹Ÿåˆç²¾åº¦ï¼Œå•ä½åƒç´ 

    è¿”å›:
        fitted_contours: list of np.ndarray, æ‹Ÿåˆåçš„è½®å»“ [outer, inner]
    """
    contours, _ = cv2.findContours(surface_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    print("æ€»å…±æ‰¾åˆ°è½®å»“æ•°é‡ï¼š", len(contours))

    if len(contours) < 1:
        return [], []

    # æŒ‰é¢ç§¯æ’åºï¼ˆå¤§åˆ°å°ï¼‰ï¼Œé€šå¸¸æœ€å¤§çš„æ˜¯å¤–è½®å»“ï¼Œç¬¬äºŒå¤§æ˜¯å†…è½®å»“
    contours = sorted(contours, key=cv2.contourArea, reverse=True)

    fitted_contours = []
    for i in range(min(2, len(contours))):  # åªå¤„ç†å‰ä¸¤ä¸ª
        cnt = contours[i]
        approx = cv2.approxPolyDP(cnt, simplify_epsilon, True)  # å¤šè¾¹å½¢æ‹Ÿåˆ
        fitted_contours.append(approx)

    return fitted_contours


def extract_outer_inner_contours_002(surface_mask, simplify_epsilon=0.02):
    """
    æ”¹è¿›ç‰ˆï¼šç”¨å‡¸åŒ…+åŠ¨æ€epsilonå¼ºåˆ¶æ‹Ÿåˆå››è¾¹å½¢è½®å»“
    """
    contours, hierarchy = cv2.findContours(surface_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    print(f"æ‰¾åˆ°è½®å»“æ•°é‡ï¼š{len(contours)}ï¼Œå±‚çº§ç»“æ„ï¼š{hierarchy}")

    fitted_contours = []
    if len(contours) == 0:
        return fitted_contours

    # æŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åº
    contours = sorted(contours, key=cv2.contourArea, reverse=True)

    for i in range(min(2, len(contours))):  # åªå¤„ç†å‰ä¸¤ä¸ªæœ€å¤§è½®å»“
        cnt = contours[i]

        # æ­¥éª¤1ï¼šè®¡ç®—å‡¸åŒ…ï¼ˆæ¶ˆé™¤å‡¹é™·ï¼‰
        hull = cv2.convexHull(cnt)

        # æ­¥éª¤2ï¼šåŠ¨æ€è®¡ç®—epsilonï¼ˆåŸºäºå‘¨é•¿æ¯”ä¾‹ï¼‰
        perimeter = cv2.arcLength(hull, True)
        epsilon = simplify_epsilon * perimeter  # å…³é”®å‚æ•°ï¼Œå¯è°ƒæ•´

        # æ­¥éª¤3ï¼šå¤šè¾¹å½¢è¿‘ä¼¼
        approx = cv2.approxPolyDP(hull, epsilon, closed=True)

        # æ­¥éª¤4ï¼šå¼ºåˆ¶å››è¾¹å½¢ï¼ˆå¦‚æœé¡¶ç‚¹è¶…è¿‡4ï¼Œé‡æ–°æ‹Ÿåˆï¼‰
        if len(approx) > 4:
            # å¦‚æœé¡¶ç‚¹è¿‡å¤šï¼Œé€‚å½“å¢å¤§epsilon
            epsilon *= 1.5
            approx = cv2.approxPolyDP(hull, epsilon, closed=True)

        print(f"è½®å»“{i}æ‹Ÿåˆåé¡¶ç‚¹æ•°ï¼š{len(approx)}")
        fitted_contours.append(approx)

    return fitted_contours


def fit_plane_and_extract_height_map(roi_p3d: np.ndarray,
                                     distance_threshold,
                                     ransac_n: int = 65,
                                     num_iterations: int = 1000,
                                     visualize: bool = True):
    """
    å¯¹ç‚¹äº‘ ROI ä½¿ç”¨ RANSAC æ‹Ÿåˆå¹³é¢ï¼Œæå–å¹³é¢åŒºåŸŸé«˜åº¦å›¾å¹¶å¯è§†åŒ–

    å‚æ•°:
        roi_p3d: (H, W, 3) çš„ç‚¹äº‘æ•°æ®ï¼ˆå•ä½ mmï¼‰
        distance_threshold: RANSAC æ‹Ÿåˆå¹³é¢å†…ç‚¹æœ€å¤§è·ç¦»ï¼ˆmmï¼‰
        ransac_n: æ‹Ÿåˆå¹³é¢æ—¶ç”¨äºæœ€å°æ‹Ÿåˆçš„ç‚¹æ•°
        num_iterations: RANSAC æœ€å¤§è¿­ä»£æ¬¡æ•°
        visualize: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–çª—å£

    è¿”å›:
        plane_model: å¹³é¢å‚æ•° [a, b, c, d]
        inlier_mask: (H, W) çš„ bool æ©ç ï¼ŒTrue è¡¨ç¤ºå±äºå¹³é¢
        height_map: (H, W) çš„ float é«˜åº¦å›¾ï¼Œä»…å¹³é¢åŒºåŸŸæœ‰æ•ˆ
    """
    H, W, _ = roi_p3d.shape
    valid_mask = np.all(~np.isnan(roi_p3d), axis=2) & (roi_p3d[:, :, 2] > 0)
    points = roi_p3d[valid_mask].reshape(-1, 3)

    if len(points) < ransac_n:
        print("ç‚¹äº‘ä¸­æœ‰æ•ˆç‚¹ä¸è¶³ä»¥æ‹Ÿåˆå¹³é¢")
        return None, None, None

    # Open3D ç‚¹äº‘æ„å»ºä¸æ‹Ÿåˆ
    pcd = open3d.geometry.PointCloud()
    pcd.points = open3d.utility.Vector3dVector(points / 1000.0)  # è½¬ä¸ºç±³
    plane_model, inliers = pcd.segment_plane(distance_threshold / 1000.0, ransac_n, num_iterations)
    a, b, c, d = plane_model
    print(f"æ‹Ÿåˆå¹³é¢æ–¹ç¨‹: {a:.4f}x + {b:.4f}y + {c:.4f}z + {d:.4f} = 0")

    # inlier mask æ˜ å°„å› 2D å›¾åƒ
    inlier_mask = np.zeros((H, W), dtype=bool)
    inlier_points = np.asarray(pcd.points)[inliers] * 1000  # è½¬å› mm

    # æ„å»ºå¿«é€Ÿ KDTree æ¥æ˜ å°„å›åƒç´ ä½ç½®
    from scipy.spatial import cKDTree
    tree = cKDTree(points)
    _, indices = tree.query(inlier_points, k=1)

    flat_indices = np.flatnonzero(valid_mask)
    selected_pixels = flat_indices[indices]
    y_coords, x_coords = np.unravel_index(selected_pixels, (H, W))
    inlier_mask[y_coords, x_coords] = True

    # --- é«˜åº¦å›¾è®¡ç®— ---
    height_map = np.zeros((H, W), dtype=np.float32)
    normal = np.array([a, b, c])
    norm = np.linalg.norm(normal)
    normal_unit = normal / norm

    # æå–å¹³é¢ç‚¹
    yy, xx = np.where(inlier_mask)
    pts = roi_p3d[yy, xx, :]
    dot = pts @ normal.T
    signed_dist = (dot + d * 1000) / norm
    height_map[yy, xx] = signed_dist

    # --- å¯è§†åŒ– ---
    if visualize:
        color_map = np.zeros((H, W, 3), dtype=np.uint8)
        norm_heights = (signed_dist - signed_dist.min()) / (signed_dist.max() - signed_dist.min() + 1e-6)
        height_img = np.uint8(norm_heights * 255)
        color = cv2.applyColorMap(height_img, cv2.COLORMAP_JET)
        color = color.reshape(-1, 3)  # ğŸ”§ ä¿®å¤è¿™é‡Œçš„ shape
        color_map[yy, xx] = color

        vis_mask = np.zeros((H, W), dtype=np.uint8)
        vis_mask[yy, xx] = 255

        contour_vis = cv2.cvtColor(vis_mask, cv2.COLOR_GRAY2BGR)
        contours, _ = cv2.findContours(vis_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(contour_vis, contours, -1, (0, 255, 0), 2)

        # cv2.imshow("Inlier Mask", vis_mask)
        # cv2.imshow("Relative Height Map", color_map)
        # cv2.imshow("Plane Region Contour", contour_vis)

    # FIXME plane_model, inlier_mask, height_map, conter_vis = fit_plane_and_extract_height_map( ValueError: not enough values to unpack(expected 4, got 3)
    return plane_model, inlier_mask, height_map, contour_vis


def extract_skeleton_from_contour_image(image: np.ndarray, invert_binary=True):
    """
    ä»å›¾åƒä¸­æå–ä¸­å¿ƒå°é—­è½®å»“åŒºåŸŸå¹¶ç”Ÿæˆéª¨æ¶çº¿å›¾åƒï¼Œç”¨OpenCVæ˜¾ç¤º

    å‚æ•°:
        image: è¾“å…¥å›¾åƒï¼Œå¯ä»¥æ˜¯å½©è‰² (H, W, 3) æˆ–ç°åº¦ (H, W)
        invert_binary: æ˜¯å¦è¿›è¡ŒäºŒå€¼å›¾åè½¬ï¼ˆé€‚ç”¨äºç™½åº•é»‘è½®å»“çš„å›¾ï¼‰

    æ˜¾ç¤º:
        ä½¿ç”¨ OpenCV æ˜¾ç¤ºæ©ç åŒºåŸŸå’Œéª¨æ¶çƒ­åŠ›å›¾å åŠ å›¾
    """

    # å¦‚æœæ˜¯å½©è‰²å›¾ï¼Œè½¬æ¢ä¸ºç°åº¦
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()

    # äºŒå€¼åŒ–
    threshold_type = cv2.THRESH_BINARY_INV if invert_binary else cv2.THRESH_BINARY
    _, binary = cv2.threshold(gray, 127, 255, threshold_type)

    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        print("æœªæ‰¾åˆ°è½®å»“")
        return None

    # æ‰¾åˆ°æœ€æ¥è¿‘å›¾åƒä¸­å¿ƒçš„è½®å»“
    image_center = np.array([gray.shape[1] // 2, gray.shape[0] // 2])
    contour_centers = [np.mean(cnt[:, 0, :], axis=0) for cnt in contours]
    distances = [np.linalg.norm(c - image_center) for c in contour_centers]
    closest_index = np.argmin(distances)
    selected_contour = contours[closest_index]

    # åˆ›å»ºæ©ç å¹¶å¡«å……é€‰ä¸­è½®å»“åŒºåŸŸ
    mask = np.zeros_like(binary)
    cv2.drawContours(mask, [selected_contour], -1, 255, thickness=cv2.FILLED)

    # æå–éª¨æ¶
    masked_binary = cv2.bitwise_and(binary, mask)
    # skeleton = skeletonize(masked_binary > 0)

    # çƒ­åŠ›å›¾å åŠ æ•ˆæœ
    # skeleton_uint8 = np.uint8(skeleton * 255)
    # skeleton_colored = cv2.applyColorMap(skeleton_uint8, cv2.COLORMAP_HOT)

    # æ˜¾ç¤ºåŸå›¾ + éª¨æ¶çƒ­åŠ›å›¾å åŠ 
    # image_color = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    # overlay = cv2.addWeighted(image_color, 0.7, skeleton_colored, 0.7, 0)

    # æ˜¾ç¤ºå›¾åƒ
    cv2.imshow("Selected Region Binary", masked_binary)
    # cv2.imshow("Skeleton Overlay", overlay)

    # å¯è§†åŒ–ï¼Œå åŠ è½®å»“çº¿
    contours = extract_outer_inner_contours(masked_binary)
    # contours = extract_outer_inner_contours_002(surface_mask)
    vis_img = cv2.cvtColor(masked_binary, cv2.COLOR_GRAY2BGR)

    colors = [(0, 0, 255), (0, 255, 0)]  # å¤–è½®å»“çº¢è‰²ï¼Œå†…è½®å»“ç»¿è‰²
    # for contour in contours:
    #     print(contour)
    for i, contour in enumerate(contours):
        cv2.drawContours(vis_img, [contour], -1, colors[i], 2)
        # cv2.drawContours(vis, [contour], -1, colors[i], 2)

    # è®¡ç®—å¹¶ç»˜åˆ¶ä¸­è½´çº¿()
    dilation = None
    if len(contours) >= 2:
        outer_cnt = contours[0]
        inner_cnt = contours[1]

        # åˆ›å»ºç¯çŠ¶åŒºåŸŸæ©è†œ
        ring_mask = np.zeros_like(masked_binary, dtype=np.uint8)
        cv2.drawContours(ring_mask, [outer_cnt], -1, 255, cv2.FILLED)  # å¡«å……å¤–è½®å»“
        cv2.drawContours(ring_mask, [inner_cnt], -1, 0, cv2.FILLED)  # æŒ–ç©ºå†…è½®å»“

        # è‡ªå®šä¹‰éª¨æ¶æå–å‡½æ•°
        def skeletonize_(img):
            skel = np.zeros(img.shape, np.uint8)
            img = img.copy()
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))
            while True:
                eroded = cv2.erode(img, kernel)
                temp = cv2.dilate(eroded, kernel)
                temp = cv2.subtract(img, temp)
                skel = cv2.bitwise_or(skel, temp)
                img = eroded.copy()
                if cv2.countNonZero(img) == 0:
                    break
            return skel

        # æå–éª¨æ¶
        thinned = skeletonize_(ring_mask)  # (480,560)

        # å°†éª¨æ¶ç»˜åˆ¶ä¸ºè“è‰²ï¼ˆBGRæ ¼å¼ï¼‰
        vis_img[thinned != 0] = (255, 0, 0)  # è“è‰²é€šé“

        # åˆ›å»ºé»‘è‰²èƒŒæ™¯è§†å›¾
        black_view = np.zeros_like(vis_img)
        # å°†éª¨æ¶ç»˜åˆ¶ä¸ºè“è‰²ï¼ˆBGRæ ¼å¼ï¼‰åœ¨é»‘è‰²è§†å›¾ä¸Š
        black_view[thinned != 0] = (255, 255, 255)  # white

        # æ˜¾ç¤ºç‹¬ç«‹éª¨æ¶è§†å›¾
        cv2.imshow("Independent Skeleton View", black_view)

        # è†¨èƒ€æ“ä½œï¼Œæ‰©å¤§éª¨æ¶çº¿ (è…èš€ç›´æ¥æ¶ˆå¤±)
        _copy = black_view.copy()
        kernel = np.ones((3, 3), np.uint8)
        dilation = cv2.dilate(_copy, kernel)
        cv2.imshow("dilation", dilation)

        # update
        # è½¬ç°åº¦
        if len(dilation.shape) == 3:
            dilation_gray = cv2.cvtColor(dilation, cv2.COLOR_BGR2GRAY)
        else:
            dilation_gray = dilation

        #
        _, binary = cv2.threshold(dilation_gray, 127, 255, cv2.THRESH_BINARY)

        return dilation

    return dilation



def main():
    cl = PercipioSDK()

    dev_list = cl.ListDevice()
    for idx in range(len(dev_list)):
        dev = dev_list[idx]
        print('{} -- {} \t {}'.format(idx, dev.id, dev.iface.id))
    if len(dev_list) == 0:
        print('no device')
        return
    if len(dev_list) == 1:
        selected_idx = 0
    else:
        selected_idx = int(input('select a device:'))
    if selected_idx < 0 or selected_idx >= len(dev_list):
        return

    sn = dev_list[selected_idx].id

    handle = cl.Open(sn)
    if not cl.isValidHandle(handle):
        err = cl.TYGetLastErrorCodedescription()
        print('no device found : ', end='')
        print(err)
        return

    event = PythonPercipioDeviceEvent()
    cl.DeviceRegiststerCallBackEvent(event)

    ## START
    color_fmt_list = cl.DeviceStreamFormatDump(handle, PERCIPIO_STREAM_COLOR)
    if len(color_fmt_list) == 0:
        print('device has no color stream.')
        return

    print('color image format list:')
    for idx in range(len(color_fmt_list)):
        fmt = color_fmt_list[idx]
        print('\t{} -size[{}x{}]\t-\t desc:{}'.format(idx, cl.Width(fmt), cl.Height(fmt), fmt.getDesc()))
    cl.DeviceStreamFormatConfig(handle, PERCIPIO_STREAM_COLOR, color_fmt_list[0])

    depth_fmt_list = cl.DeviceStreamFormatDump(handle, PERCIPIO_STREAM_DEPTH)
    if len(depth_fmt_list) == 0:
        print('device has no depth stream.')
        return

    print('depth image format list:')
    for idx in range(len(depth_fmt_list)):
        fmt = depth_fmt_list[idx]
        print('\t{} -size[{}x{}]\t-\t desc:{}'.format(idx, cl.Width(fmt), cl.Height(fmt), fmt.getDesc()))

    cl.DeviceStreamFormatConfig(handle, PERCIPIO_STREAM_DEPTH, depth_fmt_list[0])

    err = cl.DeviceLoadDefaultParameters(handle)
    if err:
        print('Load default parameters fail: ', end='')
        print(cl.TYGetLastErrorCodedescription())
    else:
        print('Load default parameters successful')

    # è¯»å–æ ¡å‡†æ•°æ®
    scale_unit = cl.DeviceReadCalibDepthScaleUnit(handle)
    print('depth image scale unit :{}'.format(scale_unit))  # 0.125
    depth_calib = cl.DeviceReadCalibData(handle, PERCIPIO_STREAM_DEPTH)
    color_calib = cl.DeviceReadCalibData(handle, PERCIPIO_STREAM_COLOR)
    depth_calib_data = cl.DeviceReadCalibData(handle, PERCIPIO_STREAM_DEPTH)
    depth_calib_width = depth_calib_data.Width()
    depth_calib_height = depth_calib_data.Height()
    depth_calib_intr = depth_calib_data.Intrinsic()
    depth_calib_extr = depth_calib_data.Extrinsic()
    depth_calib_dis = depth_calib_data.Distortion()

    err = cl.DeviceStreamEnable(handle, PERCIPIO_STREAM_COLOR | PERCIPIO_STREAM_DEPTH)
    if err:
        print('device stream enable err:{}'.format(err))
        return

    print('{} -- {} \t'.format(0, "Map depth to color coordinate(suggest)"))
    print('{} -- {} \t'.format(1, "Map color to depth coordinate"))
    # æ¨¡å¼0ï¼šå°†æ·±åº¦å›¾æ˜ å°„åˆ°å½©è‰²å›¾åæ ‡ç³»ï¼ˆå¸¸ç”¨ï¼Œå½©è‰²å›¾åˆ†è¾¨ç‡é€šå¸¸æ›´é«˜ï¼‰ã€‚
    # æ¨¡å¼1ï¼šå°†å½©è‰²å›¾æ˜ å°„åˆ°æ·±åº¦å›¾åæ ‡ç³»ã€‚
    # registration_mode = int(input('select registration mode(0 or 1):'))
    # if selected_idx < 0 or selected_idx >= 2:
    #     registration_mode = 0
    registration_mode = 2

    cl.DeviceStreamOn(handle)

    # ç‚¹äº‘æ•°æ®
    pointcloud_data_arr = pointcloud_data_list()

    img_registration_depth = image_data()
    img_registration_render = image_data()
    img_parsed_color = image_data()
    img_undistortion_color = image_data()
    img_registration_color = image_data()

    count = 0

    # æ·±åº¦å›¾åˆ†è¾¨ç‡ï¼š(1920, 2560)
    # ç‚¹äº‘å›¾åˆ†è¾¨ç‡ï¼š(1536, 2048ï¼‰
    ROI_X1, ROI_Y1 = 900, 800  # å·¦ä¸Šè§’åæ ‡
    ROI_X2, ROI_Y2 = 1600, 1400  # å³ä¸‹è§’åæ ‡

    while True:
        if event.IsOffline():
            break
        image_list = cl.DeviceStreamRead(handle, 2000)
        if len(image_list) == 2:
            frame = []
            for i in range(len(image_list)):
                frame = image_list[i]
                if frame.streamID == PERCIPIO_STREAM_DEPTH:
                    img_depth = frame
                if frame.streamID == PERCIPIO_STREAM_COLOR:
                    img_color = frame

            if registration_mode == 0:  # æ·±åº¦å›¾æ˜ å°„åˆ°å½©è‰²å›¾åæ ‡ç³»

                # æ·±åº¦æ˜ å°„åˆ°å½©è‰²åæ ‡ç³»ï¼Œå¾—åˆ° raw æ·±åº¦å’Œæ¸²æŸ“ç”¨çš„ä¼ªå½©
                cl.DeviceStreamMapDepthImageToColorCoordinate(
                    depth_calib, img_depth, scale_unit, color_calib,
                    img_color.width, img_color.height, img_registration_depth
                )
                cl.DeviceStreamDepthRender(img_registration_depth, img_registration_render)

                # åŸå§‹æ·±åº¦å›¾ï¼ˆ16bit, å•ä½ mmï¼‰
                raw_depth = img_registration_depth.as_nparray()  # (1920, 2560, 1)
                print('depth image scale unit :{}'.format(raw_depth.shape))
                roi_raw_depth = raw_depth[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2]
                print('roi depth image shape :{}'.format(roi_raw_depth.shape))  # (600, 700, 1)

                roi_raw_depth = np.squeeze(roi_raw_depth)

                valid_mask = roi_raw_depth > 0
                if not np.any(valid_mask):
                    print("æ²¡æœ‰æœ‰æ•ˆæ·±åº¦ï¼")
                    continue
                min_depth = np.min(roi_raw_depth[valid_mask])
                thickness = 50
                lower = max(min_depth - thickness, 1)
                upper = min_depth + thickness
                print("lower:{} upper:{}".format(lower, upper))

                layer_mask = ((roi_raw_depth >= lower) & (roi_raw_depth <= upper)).astype(np.uint8) * 255
                # cv2.imshow('Layer Mask', layer_mask)
                print("layer_mask éé›¶åƒç´ æ•°é‡: ", np.count_nonzero(layer_mask))

                contours, _ = cv2.findContours(layer_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                print("æ‰¾åˆ°è½®å»“æ•°é‡: ", len(contours))

                # æ¸²æŸ“å¯è§†åŒ–å›¾åƒ
                # cl.DeviceStreamDepthRender(img_registration_depth, img_registration_render)
                mat_depth_render = img_registration_render.as_nparray()  # (1920, 2560, 3)
                # cv2.imshow("mat_depth_render", mat_depth_render)
                cv2.rectangle(mat_depth_render, (ROI_X1, ROI_Y1), (ROI_X2, ROI_Y2), (0, 255, 0), 2)
                roi_depth = mat_depth_render[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2]  # [800:1400,900,1600] => [600,700]
                # cv2.imshow('ROI Depth', roi_depth)
                print(roi_depth.shape)  # (600, 700, 3)

                roi_depth_vis = roi_depth.copy()
                # cv2.drawContours(vis, contours, -1, (255, 0, 0), 2)
                cv2.imshow('ROI Depth VIS', roi_depth_vis)  # (600,700,3)

                # ç‚¹äº‘è½¬æ¢
                cl.DeviceStreamMapDepthImageToPoint3D(frame, depth_calib_data, scale_unit, pointcloud_data_arr)
                sz = pointcloud_data_arr.size()
                print('get p3d size : {}'.format(sz))  # get p3d size : 3145728
                p3d_nparray = pointcloud_data_arr.as_nparray()  # (1536, 2048, 3)

                # â˜…â˜…â˜… è‡ªåŠ¨ç¼©æ”¾æ¯”ä¾‹è®¡ç®—
                scale_x = p3d_nparray.shape[1] / raw_depth.shape[1]  # 2048 / 2560 = 0.8
                scale_y = p3d_nparray.shape[0] / raw_depth.shape[0]  # 1536 / 1920 = 0.8

                # â˜…â˜…â˜… æ ¹æ®æ·±åº¦ ROI æ˜ å°„è®¡ç®—å‡ºç‚¹äº‘ ROI çš„åæ ‡
                ROI_PCD_X1 = int(ROI_X1 * scale_x)  # 900 * 0.8 = 720
                ROI_PCD_X2 = int(ROI_X2 * scale_x)  # 1600 * 0.8 = 1280
                ROI_PCD_Y1 = int(ROI_Y1 * scale_y)  # 800 * 0.8 = 640
                ROI_PCD_Y2 = int(ROI_Y2 * scale_y)  # 1400 * 0.8 = 1120
                # Y2-Y1 = 480
                # X2-X1 = 560

                print("æ˜ å°„åç‚¹äº‘ROIåæ ‡ï¼š({}, {}) ~ ({}, {})".format(ROI_PCD_X1, ROI_PCD_Y1, ROI_PCD_X2, ROI_PCD_Y2))
                # æ˜ å°„åç‚¹äº‘ROIåæ ‡ï¼š(720, 640) ~ (1280, 1120)

                # â˜…â˜…â˜… ROI å¯¹é½æå–
                roi_p3d = p3d_nparray[ROI_PCD_Y1:ROI_PCD_Y2, ROI_PCD_X1:ROI_PCD_X2, :]  # [640:1120,720:1280]
                print("roi_p3d_shape", roi_p3d.shape)  # (480, 560, 3)
                cv2.imshow("roi_p3d", roi_p3d)

                # *** (480,560,3) => (600,700,3)
                # resize åˆ° (600, 700) å¯¹é½æ·±åº¦å›¾ ROI å½¢çŠ¶
                # roi_p3d_aligned = cv2.resize(roi_p3d, (roi_raw_depth.shape[1], roi_raw_depth.shape[0]),
                #                              interpolation=cv2.INTER_NEAREST)
                # print("roi_3d_shape:", roi_p3d_aligned.shape)  # (600, 700, 3)
                # cv2.imshow("roi_p3d_aligned", roi_p3d_aligned)
                # cv2.imshow('p3d_z', roi_p3d_aligned[:, :, 2].astype(np.uint16))  # æ˜¾ç¤º z å€¼

                # FIXME plane_model, inlier_mask, height_map, conter_vis = fit_plane_and_extract_height_map( ValueError: not enough values to unpack(expected 4, got 3)
                # RANSAC æ‹Ÿåˆå¹³é¢ + æ©ç ç”Ÿæˆ + å¯è§†åŒ–æ¸²æŸ“
                plane_model, inlier_mask, height_map, conter_vis = fit_plane_and_extract_height_map(
                    roi_p3d,
                    # roi_p3d_aligned,
                    distance_threshold=3.8,
                    visualize=True
                )

                # éª¨æ¶æå–
                skeletonize_vis = extract_skeleton_from_contour_image(conter_vis)
                # cv2.imshow("skeletonize_vis", skeletonize_vis)

            elif registration_mode == 1:  # å½©è‰²å›¾æ˜ å°„åˆ°æ·±åº¦å›¾åæ ‡ç³»ã€‚
                cl.DeviceStreamImageDecode(img_color, img_parsed_color)
                cl.DeviceStreamDoUndistortion(color_calib, img_parsed_color, img_undistortion_color)

                # å°†å½©è‰²å›¾åƒæ˜ å°„åˆ°æ·±åº¦åæ ‡ç³»ï¼Œé€‚ç”¨äºéœ€è¦æ·±åº¦å›¾åˆ†è¾¨ç‡çš„åœºæ™¯ã€‚
                cl.DeviceStreamMapRGBImageToDepthCoordinate(depth_calib, img_depth, scale_unit, color_calib,
                                                            img_undistortion_color, img_registration_color)

                cl.DeviceStreamDepthRender(img_depth, img_registration_render)
                mat_depth_render = img_registration_render.as_nparray()
                cv2.imshow('depth', mat_depth_render)

                mat_registration_color = img_registration_color.as_nparray()
                cv2.imshow('registration rgb', mat_registration_color)

            elif registration_mode == 2:  # å½©è‰²ç‚¹äº‘æ˜¾ç¤º

                ROI_X1, ROI_Y1 = 800, 700  # å·¦ä¸Šè§’åæ ‡
                ROI_X2, ROI_Y2 = 1200, 1050  # å³ä¸‹è§’åæ ‡

                # ç‚¹äº‘è½¬æ¢
                cl.DeviceStreamMapDepthImageToPoint3D(frame, depth_calib_data, scale_unit, pointcloud_data_arr)
                sz = pointcloud_data_arr.size()
                print('get p3d size : {}'.format(sz))  # get p3d size : 3145728
                p3d_nparray = pointcloud_data_arr.as_nparray()  # (1536, 2048, 3)
                # cv2.imshow("p3d_nparray", p3d_nparray)

                # æ·±åº¦å›¾æ˜¾ç¤º
                cl.DeviceStreamDepthRender(frame, img_registration_depth)
                depth = img_registration_depth.as_nparray()
                # cv2.imshow('depth', depth)  # (1536, 2048, 3)
                # Depth at (1000, 1000): R=35, G=255, B=219

                # roi depth
                roi_raw_depth = depth[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2]
                # print('roi depth image shape :{}'.format(roi_raw_depth.shape))
                cv2.imshow("roi_raw_depth", roi_raw_depth)

                # roi cloud
                roi_cloud = p3d_nparray[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2]
                cv2.imshow("roi_p3d_nparray", roi_cloud)

                # process
                plane_model, inlier_mask, height_map, conter_vis = fit_plane_and_extract_height_map(
                    roi_cloud,
                    # roi_p3d_aligned,
                    distance_threshold=3.8,
                    visualize=True
                )
                dilation_vis = extract_skeleton_from_contour_image(conter_vis)

                if dilation_vis is not None:
                    if dilation_vis.ndim == 3 and dilation_vis.shape[2] == 3:
                        if np.array_equal(dilation_vis[:, :, 0], dilation_vis[:, :, 1]) and \
                                np.array_equal(dilation_vis[:, :, 0], dilation_vis[:, :, 2]):
                            dilation_vis = dilation_vis[:, :, 0].copy()
                        else:
                            dilation_vis = cv2.cvtColor(dilation_vis, cv2.COLOR_BGR2GRAY)

                    # resize to depth size
                    full_mask = np.zeros((depth.shape[0], depth.shape[1]), dtype=dilation_vis.dtype)
                    full_mask[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2] = dilation_vis
                    # cv2.imshow("full_mask", full_mask)

                    # create red mask
                    mask_color = np.zeros_like(depth)
                    mask_color[full_mask == 255] = (102, 255, 255)  # G
                    # print("green pixel count:", np.sum(np.all(mask_color == (0, 255, 0), axis=2))) # 3233
                    # cv2.imshow("mask_color", mask_color)
                    # addWeight
                    overlay = cv2.addWeighted(depth, 0.6, mask_color, 0.4, 0)
                    # draw
                    cv2.rectangle(overlay, (ROI_X1, ROI_Y1), (ROI_X2, ROI_Y2), (255, 0, 0), 2)
                    # cv2.imshow("result", overlay)

            k = cv2.waitKey(10)
            if k == ord('q'):
                break

    cl.DeviceStreamOff(handle)
    cl.Close(handle)


if __name__ == '__main__':
    main()
