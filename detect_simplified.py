import numpy as np
import pcammls
from pcammls import *
import cv2
import open3d
from skimage.morphology import skeletonize
from scipy.ndimage import label
from scipy.spatial import cKDTree


class PythonPercipioDeviceEvent(pcammls.DeviceEvent):
    Offline = False

    def __init__(self):
        pcammls.DeviceEvent.__init__(self)

    def run(self, handle, eventID):
        if eventID == TY_EVENT_DEVICE_OFFLINE:
            print('=== Event Callback: Device Offline!')
            self.Offline = True
        return 0

    def IsOffline(self):
        return self.Offline

### --- æ–°å¢è¾…åŠ©å‡½æ•°ï¼šç”¨äºä¿æŒçºµæ¨ªæ¯”çš„ç¼©æ”¾ --- ###
def resize_with_padding(img, target_shape):
    """
    é€šè¿‡æ·»åŠ é»‘è¾¹ï¼ˆLetterboxingï¼‰æ¥ç¼©æ”¾å›¾åƒï¼ŒåŒæ—¶ä¿æŒå…¶åŸå§‹çºµæ¨ªæ¯”ã€‚
    è¿™å¯ä»¥é˜²æ­¢åœ¨ç¼©æ”¾è¿‡ç¨‹ä¸­å‘ç”Ÿä¸å¸Œæœ›çš„æ‹‰ä¼¸æˆ–å‹ç¼©ï¼Œä»è€Œè§£å†³å åŠ æ—¶çš„ä½ç½®åç§»é—®é¢˜ã€‚

    :param img: éœ€è¦ç¼©æ”¾çš„æºå›¾åƒã€‚
    :param target_shape: (height, width) æ ¼å¼çš„ç›®æ ‡å°ºå¯¸ã€‚
    :return: ç»è¿‡ç¼©æ”¾å’Œå¡«å……åï¼Œå°ºå¯¸ä¸ target_shape å®Œå…¨ä¸€è‡´çš„æ–°å›¾åƒã€‚
    """
    target_h, target_w = target_shape
    img_h, img_w = img.shape[:2]

    # è®¡ç®—ç›®æ ‡å’Œæºå›¾åƒçš„çºµæ¨ªæ¯”
    target_aspect = target_w / target_h
    img_aspect = img_w / img_h

    if img_aspect > target_aspect:
        # æºå›¾åƒæ¯”ç›®æ ‡â€œæ›´å®½â€ï¼Œå› æ­¤ä»¥å®½åº¦ä¸ºåŸºå‡†è¿›è¡Œç¼©æ”¾
        new_w = target_w
        new_h = int(new_w / img_aspect)
    else:
        # æºå›¾åƒæ¯”ç›®æ ‡â€œæ›´é«˜â€ï¼Œå› æ­¤ä»¥é«˜åº¦ä¸ºåŸºå‡†è¿›è¡Œç¼©æ”¾
        new_h = target_h
        new_w = int(new_h * img_aspect)

    # ä½¿ç”¨è®¡ç®—å‡ºçš„æ–°å°ºå¯¸è¿›è¡Œç¼©æ”¾ï¼Œè¿™ä¼šä¿æŒåŸå§‹æ¯”ä¾‹
    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_NEAREST)

    # åˆ›å»ºä¸€ä¸ªç¬¦åˆç›®æ ‡å°ºå¯¸çš„é»‘è‰²èƒŒæ™¯ç”»å¸ƒ
    padded_img = np.zeros(target_shape, dtype=img.dtype)

    # è®¡ç®—å°†ç¼©æ”¾åå›¾åƒæ”¾ç½®åœ¨ç”»å¸ƒä¸­å¿ƒæ‰€éœ€çš„åç§»é‡ï¼ˆå³é»‘è¾¹çš„å°ºå¯¸ï¼‰
    pad_top = (target_h - new_h) // 2
    pad_left = (target_w - new_w) // 2

    # å°†ç¼©æ”¾åçš„å›¾åƒç²˜è´´åˆ°ç”»å¸ƒä¸­å¿ƒ
    padded_img[pad_top:pad_top + new_h, pad_left:pad_left + new_w] = resized

    return padded_img


### --- æ–°å¢å‡½æ•°ï¼šç”¨äºç”Ÿæˆæ— ç•¸å˜æ©ç çš„æ ¸å¿ƒ --- ###
def create_corrected_mask(roi_p3d_rotated, depth_margin, pixel_size_mm=0.5):
    """
    (æ–°æ–¹æ¡ˆ) é€šè¿‡æ­£äº¤æŠ•å½±å’Œå½¢æ€å­¦é—­è¿ç®—ï¼Œä»æ—‹è½¬åçš„ç‚¹äº‘åˆ›å»ºæ— ç•¸å˜ä¸”å¯†å®çš„è¡¨é¢æ©ç ã€‚
    è¿™ä¸ªå‡½æ•°å°†æ›¿ä»£æ—§çš„ extract_nearest_surface_mask æ¥å¤„ç†æ ¡æ­£åçš„ç‚¹äº‘ã€‚

    :param roi_p3d_rotated: (H, W, 3) çš„ NumPy æ•°ç»„ï¼Œä»£è¡¨å·²ç»è¿‡æ—‹è½¬æ ¡æ­£çš„ç‚¹äº‘ROIã€‚
    :param depth_margin: ä»æœ€è¿‘è¡¨é¢æå–ç‚¹äº‘å±‚çš„åšåº¦å®¹å·® (mm)ã€‚
    :param pixel_size_mm: æ­£äº¤æŠ•å½±åï¼Œæ¯ä¸ªåƒç´ ä»£è¡¨çš„çœŸå®ä¸–ç•Œå°ºå¯¸ (mm)ã€‚
    :return: (final_mask, z_min_val)
             - final_mask: (H', W') çš„ uint8 æ•°ç»„ï¼Œæœ€ç»ˆç”Ÿæˆçš„æ— ç•¸å˜ã€å¯†å®çš„äºŒå€¼æ©ç ã€‚
             - z_min_val: æ ¡æ­£åç‚¹äº‘ä¸­çš„æœ€å°Zå€¼ã€‚
    """
    # 1. å°†ç‚¹äº‘ROIé‡å¡‘ä¸ºç‚¹åˆ—è¡¨ï¼Œå¹¶è¿‡æ»¤æ— æ•ˆç‚¹
    points = roi_p3d_rotated.reshape(-1, 3)
    valid_points = points[points[:, 2] > 0]
    if valid_points.shape[0] < 3:
        print("æ­£äº¤æŠ•å½±é”™è¯¯: æœ‰æ•ˆç‚¹æ•°é‡è¿‡å°‘ã€‚")
        return None, None

    # 2. åœ¨æ ¡æ­£åçš„Zè½´ä¸Šæ‰¾åˆ°æœ€è¿‘çš„è¡¨é¢
    z_min_val = np.min(valid_points[:, 2])
    print(f"\tæœ€è¿‘è¡¨é¢Zå€¼ (æ ¡æ­£å): {z_min_val:.2f}mm")
    surface_points = valid_points[(valid_points[:, 2] >= z_min_val) & (valid_points[:, 2] <= z_min_val + depth_margin)]
    if surface_points.shape[0] < 3:
        print("æ­£äº¤æŠ•å½±é”™è¯¯: è¡¨é¢ç‚¹æ•°é‡è¿‡å°‘ã€‚")
        return None, None

    # 3. --- æ­£äº¤æŠ•å½± ---
    # è®¡ç®—ç‚¹äº‘åœ¨çœŸå®ä¸–ç•ŒXYå¹³é¢ä¸Šçš„è¾¹ç•Œ
    x_min, y_min, _ = np.min(surface_points, axis=0)
    x_max, y_max, _ = np.max(surface_points, axis=0)

    # æ ¹æ®çœŸå®ä¸–ç•Œå°ºå¯¸å’Œè®¾å®šçš„åƒç´ åˆ†è¾¨ç‡ï¼Œè®¡ç®—æ–°æ©ç å›¾åƒçš„åƒç´ å°ºå¯¸
    width_px = int(np.ceil((x_max - x_min) / pixel_size_mm)) + 1
    height_px = int(np.ceil((y_max - y_min) / pixel_size_mm)) + 1
    if width_px <= 1 or height_px <= 1:
        return None, None

    # 4. å°†3Dè¡¨é¢ç‚¹â€œç”»â€åˆ°ä¸€ä¸ªæ–°çš„2Dç”»å¸ƒï¼ˆç¨€ç–çš„ç‚¹é›†ï¼‰ä¸Š
    point_img = np.zeros((height_px, width_px), dtype=np.uint8)
    px_coords = np.floor((surface_points[:, 0] - x_min) / pixel_size_mm).astype(int)
    py_coords = np.floor((surface_points[:, 1] - y_min) / pixel_size_mm).astype(int)
    point_img[py_coords, px_coords] = 255
    cv2.imshow("Orthographic Projection (Sparse Points)", point_img)  # ç”¨äºè°ƒè¯•ï¼Œæ˜¾ç¤ºç¨€ç–çš„ç‚¹

    # 5. --- å½¢æ€å­¦é—­è¿ç®— ---
    # è¿™æ˜¯è¿æ¥ç¨€ç–ç‚¹ï¼Œå½¢æˆå®Œæ•´è½®å»“çš„å…³é”®æ­¥éª¤
    # å†…æ ¸å¤§å°éœ€è¦æ ¹æ®ç‚¹çš„ç¨€ç–ç¨‹åº¦è¿›è¡Œè°ƒæ•´ï¼Œä¸€ä¸ªè¾ƒå¤§çš„å†…æ ¸å¯ä»¥è¿æ¥æ›´è¿œçš„ç‚¹
    kernel_size = 3  # å¯ä»¥ä» 5, 7, 9, 11 å¼€å§‹å°è¯•
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
    # è¿­ä»£æ¬¡æ•°è¶Šå¤šï¼Œå¡«å……æ•ˆæœè¶Šå¼º
    closed_img = cv2.morphologyEx(point_img, cv2.MORPH_CLOSE, kernel, iterations=4)

    print(f"\tå·²åˆ›å»ºæ— ç•¸å˜æ©ç ï¼Œå°ºå¯¸: {closed_img.shape}")
    ### å°†æ ¡æ­£åçš„æ©ç resizeå›åŸå§‹ROIçš„å°ºå¯¸ ###
    # è¿™è§£å†³äº†åç»­æ­¥éª¤ä¸­å› å°ºå¯¸ä¸åŒ¹é…å¯¼è‡´çš„ValueError
    # æ³¨æ„ï¼šè¿™å¯èƒ½ä¼šå¼•å…¥è½»å¾®çš„çºµæ¨ªæ¯”å¤±çœŸï¼Œä½†ä¿ç•™äº†æ­£ç¡®çš„æ‹“æ‰‘ç»“æ„ï¼ˆå¦‚å­”æ´ï¼‰
    ### --- å…³é”®ä¿®å¤ï¼šä½¿ç”¨å¸¦paddingçš„resizeæ¥ä¿æŒçºµæ¨ªæ¯”ï¼Œè§£å†³åç§»é—®é¢˜ --- ###
    original_roi_shape = (roi_p3d_rotated.shape[0], roi_p3d_rotated.shape[1]) # (height, width)
    resized_mask = resize_with_padding(closed_img, original_roi_shape)


    print(f"\tå·²åˆ›å»ºæ— ç•¸å˜æ©ç ï¼Œå¹¶ä» {closed_img.shape} resizeåˆ° {resized_mask.shape} ä»¥åŒ¹é…ROI")
    return resized_mask, z_min_val


def extract_nearest_surface_mask(roi_p3d_aligned, depth_margin):
    """
    ä» ROI ç‚¹äº‘ä¸­æå–æœ€æµ…è¡¨é¢çš„ maskï¼ˆåŸºäº Z å€¼å±‚æå–ï¼‰

    å‚æ•°:
        roi_p3d_aligned: np.ndarray, å½¢çŠ¶ (H, W, 3)ï¼Œç‚¹äº‘æ•°æ®
        depth_margin: å®¹å·®èŒƒå›´ï¼ˆå•ä½: mmï¼‰ï¼Œç”¨äºæ„é€ æ·±åº¦å±‚åšåº¦

    è¿”å›:
        surface_mask: np.ndarray, å½¢çŠ¶ (H, W)ï¼Œuint8 ç±»å‹äºŒå€¼æ©ç ï¼Œ255è¡¨ç¤ºæœ€æµ…å±‚åŒºåŸŸ
        z_min_val: æœ€å°æ·±åº¦å€¼ï¼ˆè·ç¦»æœ€è¿‘çš„ mm å€¼ï¼‰
    """

    # 1. æå– Z å€¼å›¾
    z_img = roi_p3d_aligned[:, :, 2].copy()
    z_img[z_img <= 0] = 0  # è¿‡æ»¤æ— æ•ˆå€¼

    valid_mask = z_img > 0
    if not np.any(valid_mask):
        print("æ— æœ‰æ•ˆæ·±åº¦å€¼")
        return None, None

    z_min_val = np.min(z_img[valid_mask])
    print("\tæœ€å°æ·±åº¦å€¼:{}mm".format(z_min_val))
    lower = z_min_val
    upper = z_min_val + depth_margin
    surface_mask = ((z_img >= lower) & (z_img <= upper)).astype(np.uint8) * 255  # äºŒå€¼æ©ç 

    return surface_mask, z_min_val

def extract_nearest_surface_mask_ransac(roi_p3d_aligned, depth_margin,
                                        ransac_iters=400,
                                        dist_thresh=0.8,
                                        front_percentile=20.0,
                                        subsample=50000,
                                        random_state=None):
    """
    ä½¿ç”¨ RANSAC åœ¨ç²—ç³™åœºæ™¯ä¸‹æå–â€œæœ€è¿‘è¡¨é¢â€çš„æ©ç ï¼ˆæ–œé¢è¿‘ç«¯å¸¦åšåº¦ï¼‰ã€‚

    å‚æ•°:
        roi_p3d_aligned: np.ndarray, (H, W, 3)ï¼ŒROI å†…ç‚¹äº‘ï¼Œå•ä½ mm
        depth_margin: floatï¼Œæœ€è¿‘è¡¨é¢æ²¿ç›¸æœº Z æ–¹å‘çš„åšåº¦é˜ˆå€¼ï¼ˆmmï¼‰
        ransac_iters: intï¼ŒRANSAC è¿­ä»£æ¬¡æ•°
        dist_thresh: floatï¼ŒRANSAC è¯„ä¼°å¹³é¢çš„æ­£äº¤è·ç¦»é˜ˆå€¼ï¼ˆmmï¼‰
        front_percentile: floatï¼Œä»…ä»é å‰çš„è¿™éƒ¨åˆ†ç™¾åˆ†ä½ï¼ˆæŒ‰Zä»å°åˆ°å¤§ï¼‰é‡Œéšæœºé‡‡æ ·æ„æ¨¡ï¼Œå‡å°‘é‡‡åˆ°èƒŒæ™¯é¢çš„æ¦‚ç‡
        subsample: intï¼Œä¸ºåŠ é€Ÿåœ¨å¤§ROIä¸‹è¿›è¡Œä¸‹é‡‡æ ·çš„ä¸Šé™ç‚¹æ•°
        random_state: Optional[int]ï¼Œéšæœºç§å­ï¼Œä¾¿äºå¤ç°å®éªŒ

    è¿”å›:
        surface_mask: np.ndarray, (H, W) uint8ï¼Œ255è¡¨ç¤ºå±äºæœ€è¿‘è¡¨é¢åŒºåŸŸ
        z_min_val: floatï¼Œæ‹Ÿåˆåå†…ç‚¹ä¸­çš„æœ€å°Zï¼ˆmmï¼‰ï¼Œä¾¿äºæ—¥å¿—/å¯¹é½å‚è€ƒ
    """
    import numpy as np

    H, W, _ = roi_p3d_aligned.shape
    z_img = roi_p3d_aligned[:, :, 2].copy()
    z_img[z_img <= 0] = 0  # è¿‡æ»¤æ— æ•ˆå€¼
    valid_mask = z_img > 0
    if not np.any(valid_mask):
        print("æ— æœ‰æ•ˆæ·±åº¦å€¼")
        return None, None

    rng = np.random.default_rng(random_state)

    # --- å‡†å¤‡ç‚¹é›† ---
    ys, xs = np.where(valid_mask)
    pts = roi_p3d_aligned[ys, xs].reshape(-1, 3)  # Nx3
    N = pts.shape[0]

    # ä»…åœ¨é å‰(front)çš„ç‚¹é‡Œé‡‡æ ·å»ºæ¨¡ï¼Œé™ä½é€‰åˆ°èƒŒæ™¯çš„æ¦‚ç‡
    z_sorted = np.sort(pts[:, 2])
    z_front_cut = z_sorted[int(np.clip((front_percentile / 100.0) * (N - 1), 0, N - 1))]
    front_idx = np.where(pts[:, 2] <= z_front_cut)[0]
    if front_idx.size < 3:
        # é€€åŒ–æƒ…å†µä¸‹æ‰©å¤§é‡‡æ ·é›†åˆ
        front_idx = np.arange(N)

    # ä¸‹é‡‡æ ·ä»¥åŠ é€Ÿ
    if N > subsample:
        keep = rng.choice(N, subsample, replace=False)
        pts_eval = pts[keep]
    else:
        pts_eval = pts

    # --- RANSAC: æ‹Ÿåˆæœ€â€œé å‰â€çš„å¤§é¢ ---
    best_inliers = None
    best_inlier_count = 0
    best_mean_z = np.inf
    best_plane = None  # (a,b,c,d) with ||(a,b,c)||=1

    for _ in range(int(ransac_iters)):
        # 1) éšæœºå–3ç‚¹(æ¥è‡ªå‰æ™¯å­é›†)æ‹Ÿåˆå€™é€‰å¹³é¢
        tri = rng.choice(front_idx, 3, replace=False)
        p1, p2, p3 = pts[tri[0]], pts[tri[1]], pts[tri[2]]
        v1, v2 = p2 - p1, p3 - p1
        n = np.cross(v1, v2)
        n_norm = np.linalg.norm(n)
        if n_norm < 1e-9:
            continue
        n = n / n_norm
        d = -np.dot(n, p1)  # å¹³é¢ ax+by+cz+d=0

        # 2) è®¡ç®—è¯„ä¼°é›†åˆ°å¹³é¢çš„æ­£äº¤è·ç¦»
        dists = np.abs(pts_eval @ n + d)  # å› ä¸ºnå•ä½åŒ–ï¼Œæ— éœ€å†é™¤ä»¥||n||
        inliers_eval = dists < dist_thresh
        inlier_count = int(inliers_eval.sum())
        if inlier_count == 0:
            continue

        # 3) åœ¨å…¨ä½“ç‚¹ä¸Šå¤æ ¸ï¼ˆåªåœ¨æ›´ä¼˜æ—¶åšï¼‰
        if inlier_count > best_inlier_count:
            dists_all = np.abs(pts @ n + d)
            inliers_all = dists_all < dist_thresh
            inlier_count_all = int(inliers_all.sum())
            mean_z = float(pts[inliers_all, 2].mean()) if inlier_count_all > 0 else np.inf

            # é€‰æ‹©ï¼šä¼˜å…ˆæ›´å¤šå†…ç‚¹ï¼›è‹¥ç›¸åŒï¼Œæ›´é å‰ï¼ˆå¹³å‡Zæ›´å°ï¼‰
            if (inlier_count_all > best_inlier_count) or \
               (inlier_count_all == best_inlier_count and mean_z < best_mean_z):
                best_inliers = inliers_all
                best_inlier_count = inlier_count_all
                best_mean_z = mean_z
                best_plane = (n, d)

    if best_inliers is None or best_inlier_count < 3:
        # RANSAC å¤±è´¥ï¼Œé€€å›åˆ°æœ€ç®€å•â€œzå±‚â€æ–¹æ³•
        z_min_val = float(np.min(pts[:, 2]))
        print("\t[RANSACå›é€€] æœ€å°æ·±åº¦å€¼:{}mm".format(z_min_val))
        lower, upper = z_min_val, z_min_val + float(depth_margin)
        surface_mask = ((z_img >= lower) & (z_img <= upper)).astype(np.uint8) * 255
        return surface_mask, z_min_val

    # --- ç”¨æœ€ä½³å†…ç‚¹åšä¸€æ¬¡ SVD ç²¾æ‹Ÿåˆå¹³é¢ ---
    inlier_pts = pts[best_inliers]
    centroid = inlier_pts.mean(axis=0)
    X = inlier_pts - centroid
    # SVD: æœ€å°å¥‡å¼‚å€¼å¯¹åº”çš„æ³•å‘
    _, _, Vt = np.linalg.svd(X, full_matrices=False)
    n_ref = Vt[-1, :]
    n_ref_norm = np.linalg.norm(n_ref)
    if n_ref_norm < 1e-9:
        # é€€åŒ–æƒ…å†µï¼šæ²¿ç”¨RANSACçš„n,d
        n_ref, d_ref = best_plane
    else:
        n_ref = n_ref / n_ref_norm
        d_ref = -np.dot(n_ref, centroid)

    # --- ç”Ÿæˆæ©ç ï¼šæ²¿ç›¸æœºZæ–¹å‘çš„â€œä¸Šè¡Œåšåº¦â€ ---
    # å¹³é¢: a x + b y + c z + d = 0
    a, b, c = n_ref
    d = d_ref

    surface_mask = np.zeros((H, W), dtype=np.uint8)
    z_min_val = float(inlier_pts[:, 2].min())
    print("\t[RANSAC] æœ€å°æ·±åº¦å€¼:{}mm".format(z_min_val))

    if abs(c) >= 1e-8:
        # å¯ç”¨ z_plane é¢„æµ‹ï¼Œä¿ç•™ z - z_plane âˆˆ [0, depth_margin]
        # å¯¹æœ‰æ•ˆåƒç´ è¿›è¡Œå‘é‡åŒ–è®¡ç®—
        xs_f = roi_p3d_aligned[valid_mask, 0]
        ys_f = roi_p3d_aligned[valid_mask, 1]
        zs_f = roi_p3d_aligned[valid_mask, 2]
        z_plane = -(a * xs_f + b * ys_f + d) / c
        dz = zs_f - z_plane
        keep = (dz >= 0.0) & (dz <= float(depth_margin))
        surface_mask[ys, xs] = (keep.astype(np.uint8) * 255)
    else:
        # å¹³é¢è¿‘ä¼¼ä¸Zè½´å¹³è¡Œï¼Œé€€è€Œç”¨â€œæ­£äº¤è·ç¦» + zé˜ˆå€¼â€çš„ä¿å®ˆåˆ¤å®š
        dists_all = np.abs(roi_p3d_aligned[:, :, 0] * a +
                           roi_p3d_aligned[:, :, 1] * b +
                           roi_p3d_aligned[:, :, 2] * c + d)
        # å–åœ¨å¹³é¢é™„è¿‘ä¸” z ä¸è¶…è¿‡æœ€è¿‘å†…ç‚¹ + depth_margin
        keep = (dists_all < float(dist_thresh)) & (z_img > 0) & (z_img <= (z_min_val + float(depth_margin)))
        surface_mask[keep] = 255

    return surface_mask, z_min_val







def extract_contours_adaptive(surface_mask, min_vertices=4, max_vertices=12, max_iterations=10,
                              initial_epsilon_factor=0.01):
    """
    è‡ªé€‚åº”è½®å»“æå–ï¼š
    é€šè¿‡è¿­ä»£å¢åŠ epsilonï¼Œå°†è½®å»“æ‹Ÿåˆåˆ°æŒ‡å®šçš„é¡¶ç‚¹æ•°èŒƒå›´å†…ï¼Œä»¥é€‚åº”åŒ…å«æ›²çº¿å’Œç›´çº¿çš„å½¢çŠ¶ã€‚

    :param surface_mask: è¾“å…¥çš„äºŒå€¼å›¾åƒæ©ç ã€‚
    :param min_vertices: æ‹Ÿåˆåå¤šè¾¹å½¢çš„æœ€å°é¡¶ç‚¹æ•°ã€‚
    :param max_vertices: æ‹Ÿåˆåå¤šè¾¹å½¢çš„æœ€å¤§é¡¶ç‚¹æ•°ã€‚
    :param max_iterations: ä¸ºæ‰¾åˆ°åˆé€‚epsilonå€¼çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚
    :param initial_epsilon_factor: åˆå§‹çš„epsilonç³»æ•°ï¼ˆç›¸å¯¹äºå‘¨é•¿ï¼‰ã€‚
    :return: åŒ…å«æ‹Ÿåˆåè½®å»“çš„åˆ—è¡¨ã€‚
    """
    contours, _ = cv2.findContours(surface_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return []

    # æŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åº
    contours = sorted(contours, key=cv2.contourArea, reverse=True)

    fitted_contours = []
    # åªå¤„ç†å‰ä¸¤ä¸ªæœ€å¤§è½®å»“
    for cnt in contours[:2]:
        # æ­¥éª¤1ï¼šè®¡ç®—å‡¸åŒ…ä»¥å¹³æ»‘è½®å»“
        hull = cv2.convexHull(cnt)
        perimeter = cv2.arcLength(hull, True)

        if perimeter == 0:
            continue

        # æ­¥éª¤2ï¼šè¿­ä»£å¯»æ‰¾æœ€ä½³epsilon
        epsilon_factor = initial_epsilon_factor
        best_approx = hull  # é»˜è®¤å€¼ä¸ºåŸå§‹å‡¸åŒ…

        for _ in range(max_iterations):
            epsilon = epsilon_factor * perimeter
            approx = cv2.approxPolyDP(hull, epsilon, closed=True)

            # å¦‚æœé¡¶ç‚¹æ•°åœ¨ç†æƒ³èŒƒå›´å†…ï¼Œåˆ™é‡‡ç”¨æ­¤ç»“æœå¹¶é€€å‡ºå¾ªç¯
            if min_vertices <= len(approx) <= max_vertices:
                best_approx = approx
                break

            # å¦‚æœé¡¶ç‚¹æ•°å¤ªå¤šï¼Œè¯´æ˜epsilonå¤ªå°ï¼Œéœ€è¦å¢åŠ å®ƒä»¥ç®€åŒ–æ›´å¤š
            if len(approx) > max_vertices:
                epsilon_factor *= 1.5  # å¢åŠ epsilonçš„ç³»æ•°
                best_approx = approx  # æš‚å­˜å½“å‰æœ€æ¥è¿‘çš„ç»“æœ
            # å¦‚æœé¡¶ç‚¹æ•°å¤ªå°‘ï¼Œè¯´æ˜epsilonè¿‡å¤§ï¼Œå·²ç»è¿‡åº¦ç®€åŒ–äº†ã€‚
            # æ­¤æ—¶å¯ä»¥åœæ­¢ï¼Œå¹¶ä½¿ç”¨ä¸Šä¸€æ¬¡è¿­ä»£çš„ç»“æœï¼ˆå¦‚æœéœ€è¦æ›´ç²¾ç¡®æ§åˆ¶ï¼‰ã€‚
            # åœ¨è¿™ä¸ªç®€åŒ–æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬åªåœ¨é¡¶ç‚¹è¿‡å¤šæ—¶è°ƒæ•´ï¼Œæœ€ç»ˆä¼šå¾—åˆ°ä¸€ä¸ªç»“æœã€‚
            else:  # len(approx) < min_vertices
                # å·²ç»è¿‡åº¦ç®€åŒ–ï¼Œè·³å‡ºå¾ªç¯ï¼Œä½¿ç”¨ä¸Šä¸€æ¬¡æˆ–å½“å‰çš„ç»“æœ
                break

        fitted_contours.append(best_approx)

    return fitted_contours


def fit_plane_and_extract_height_map(roi_p3d: np.ndarray,
                                     distance_threshold,
                                     ransac_n: int = 65,
                                     num_iterations: int = 1000,
                                     visualize: bool = True):
    """
    å¯¹ç‚¹äº‘ ROI ä½¿ç”¨ RANSAC æ‹Ÿåˆå¹³é¢ï¼Œæå–å¹³é¢åŒºåŸŸé«˜åº¦å›¾å¹¶å¯è§†åŒ–

    å‚æ•°:
        roi_p3d: (H, W, 3) çš„ç‚¹äº‘æ•°æ®ï¼ˆå•ä½ mmï¼‰
        distance_threshold: RANSAC æ‹Ÿåˆå¹³é¢å†…ç‚¹æœ€å¤§è·ç¦»ï¼ˆmmï¼‰
        ransac_n: æ‹Ÿåˆå¹³é¢æ—¶ç”¨äºæœ€å°æ‹Ÿåˆçš„ç‚¹æ•°
        num_iterations: RANSAC æœ€å¤§è¿­ä»£æ¬¡æ•°
        visualize: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–çª—å£

    è¿”å›:
        plane_model: å¹³é¢å‚æ•° [a, b, c, d]
        inlier_mask: (H, W) çš„ bool æ©ç ï¼ŒTrue è¡¨ç¤ºå±äºå¹³é¢
        height_map: (H, W) çš„ float é«˜åº¦å›¾ï¼Œä»…å¹³é¢åŒºåŸŸæœ‰æ•ˆ
        contour_vis: å¯è§†åŒ–è½®å»“å›¾åƒ (H, W, 3)
    """
    H, W, _ = roi_p3d.shape
    valid_mask = np.all(~np.isnan(roi_p3d), axis=2) & (roi_p3d[:, :, 2] > 0)
    points = roi_p3d[valid_mask].reshape(-1, 3)

    if len(points) < ransac_n:
        print("ç‚¹äº‘ä¸­æœ‰æ•ˆç‚¹ä¸è¶³ä»¥æ‹Ÿåˆå¹³é¢")
        return None, None, None,None

    # Open3D ç‚¹äº‘æ„å»ºä¸æ‹Ÿåˆ
    pcd = open3d.geometry.PointCloud()
    pcd.points = open3d.utility.Vector3dVector(points / 1000.0)  # è½¬ä¸ºç±³
    plane_model, inliers = pcd.segment_plane(distance_threshold / 1000.0, ransac_n, num_iterations)
    a, b, c, d = plane_model
    print(f"æ‹Ÿåˆå¹³é¢æ–¹ç¨‹: {a:.4f}x + {b:.4f}y + {c:.4f}z + {d:.4f} = 0")

    # inlier mask æ˜ å°„å› 2D å›¾åƒ
    inlier_mask = np.zeros((H, W), dtype=bool)
    inlier_points = np.asarray(pcd.points)[inliers] * 1000  # è½¬å› mm

    # æ„å»ºå¿«é€Ÿ KDTree æ¥æ˜ å°„å›åƒç´ ä½ç½®
    tree = cKDTree(points)
    _, indices = tree.query(inlier_points, k=1)

    flat_indices = np.flatnonzero(valid_mask)
    selected_pixels = flat_indices[indices]
    y_coords, x_coords = np.unravel_index(selected_pixels, (H, W))
    inlier_mask[y_coords, x_coords] = True

    # --- é«˜åº¦å›¾è®¡ç®— ---
    height_map = np.zeros((H, W), dtype=np.float32)
    normal = np.array([a, b, c])
    norm = np.linalg.norm(normal)
    normal_unit = normal / norm

    # æå–å¹³é¢ç‚¹
    yy, xx = np.where(inlier_mask)
    pts = roi_p3d[yy, xx, :]
    dot = pts @ normal.T
    signed_dist = (dot + d * 1000) / norm
    height_map[yy, xx] = signed_dist

    # --- å¯è§†åŒ– ---
    if visualize:
        color_map = np.zeros((H, W, 3), dtype=np.uint8)
        norm_heights = (signed_dist - signed_dist.min()) / (signed_dist.max() - signed_dist.min() + 1e-6)
        height_img = np.uint8(norm_heights * 255)
        color = cv2.applyColorMap(height_img, cv2.COLORMAP_JET)
        color = color.reshape(-1, 3)  # ğŸ”§ ä¿®å¤è¿™é‡Œçš„ shape
        color_map[yy, xx] = color

        vis_mask = np.zeros((H, W), dtype=np.uint8)
        vis_mask[yy, xx] = 255

        contour_vis = cv2.cvtColor(vis_mask, cv2.COLOR_GRAY2BGR)
        contours, _ = cv2.findContours(vis_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(contour_vis, contours, -1, (0, 255, 0), 2)

        cv2.imshow("Inlier Mask", vis_mask)
        cv2.imshow("Relative Height Map", color_map)
        cv2.imshow("Plane Region Contour", contour_vis)

    # FIXME plane_model, inlier_mask, height_map, conter_vis = fit_plane_and_extract_height_map( ValueError: not enough values to unpack(expected 4, got 3)
    return plane_model, inlier_mask, height_map, contour_vis



def overlay_skeleton_with_scaling(cl: pcammls.PercipioSDK,
                                  depth_calib,
                                  img_depth: pcammls.image_data,
                                  scale_unit: float,
                                  color_calib,
                                  img_color: pcammls.image_data,
                                  skeleton_img: np.ndarray):
    """
    ä½¿ç”¨SDKçš„åæ ‡æ˜ å°„åŠŸèƒ½ï¼Œå°†æ·±åº¦åæ ‡ç³»ä¸‹çš„éª¨æ¶å›¾ç²¾ç¡®åœ°å åŠ åˆ°å½©è‰²å›¾ä¸Šã€‚
    (ä¿®æ­£ç‰ˆï¼šè§£å†³æ©ç ä¸å½©è‰²å›¾ç»´åº¦ä¸åŒ¹é…çš„ç´¢å¼•é”™è¯¯)

    Args:
        cl: PercipioSDK å®ä¾‹.
        depth_calib: æ·±åº¦ç›¸æœºçš„æ ‡å®šæ•°æ®.
        img_depth: åŸå§‹çš„æ·±åº¦å›¾åƒæ•°æ® (å°†è¢«ä¸´æ—¶ä¿®æ”¹).
        scale_unit: æ·±åº¦å€¼ç¼©æ”¾å•ä½.
        color_calib: å½©è‰²ç›¸æœºçš„æ ‡å®šæ•°æ®.
        img_color: åŸå§‹çš„å½©è‰²å›¾åƒæ•°æ®.
        skeleton_img: åœ¨æ·±åº¦å›¾åæ ‡ç³»ä¸‹ç”Ÿæˆçš„éª¨æ¶äºŒå€¼å›¾ (uint8).
    """
    if skeleton_img is None:
        print("è¾“å…¥çš„éª¨æ¶å›¾ä¸ºç©ºï¼Œæ— æ³•å åŠ ã€‚")
        return

    # 1. å¤‡ä»½åŸå§‹æ·±åº¦æ•°æ®
    original_depth_np = img_depth.as_nparray().copy()

    # 2. åˆ›å»ºåŒ…å«çœŸå®æ·±åº¦å€¼çš„â€œä¼ªæ·±åº¦å›¾â€
    fake_depth_np = np.zeros_like(original_depth_np)
    skeleton_mask = (skeleton_img == 255)
    fake_depth_np[skeleton_mask] = original_depth_np[skeleton_mask]

    # 3. å°†ä¼ªæ·±åº¦å›¾æ•°æ®ä¸´æ—¶å†™å…¥ img_depth çš„ç¼“å†²åŒº
    img_depth.as_nparray()[:] = fake_depth_np

    # 4. è°ƒç”¨SDKå‡½æ•°è¿›è¡Œåæ ‡æ˜ å°„
    mapped_skeleton_image = pcammls.image_data()
    cl.DeviceStreamMapDepthImageToColorCoordinate(
        depth_calib, img_depth, scale_unit, color_calib,
        img_color.width, img_color.height, mapped_skeleton_image
    )

    # 5. ç«‹å³æ¢å¤åŸå§‹æ·±åº¦æ•°æ®
    img_depth.as_nparray()[:] = original_depth_np

    # 6. ä»æ˜ å°„ç»“æœä¸­ç”Ÿæˆæœ€ç»ˆçš„ã€å¯¹é½çš„äºŒå€¼æ©ç 
    mapped_skeleton_np = mapped_skeleton_image.as_nparray()
    if mapped_skeleton_np is None:
        print("åæ ‡æ˜ å°„å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå åŠ å›¾ã€‚")
        return

    final_aligned_mask = (mapped_skeleton_np > 0).astype(np.uint8) * 255

    # 7. è§£ç å½©è‰²å›¾å¹¶è¿›è¡Œå åŠ 
    decoded_color = pcammls.image_data()
    cl.DeviceStreamImageDecode(img_color, decoded_color)
    color_arr = decoded_color.as_nparray()

    overlay_color = np.zeros_like(color_arr)

    # --- ä¿®æ­£ IndexError çš„æ ¸å¿ƒä»£ç  ---
    # åˆ›å»ºå¸ƒå°”æ©ç 
    boolean_mask = (final_aligned_mask == 255)
    # æ£€æŸ¥æ©ç æ˜¯å¦ä¸º (H, W, 1) çš„3Då½¢çŠ¶ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å‹ç¼©ä¸º (H, W) çš„2Då½¢çŠ¶
    if boolean_mask.ndim == 3 and boolean_mask.shape[2] == 1:
        boolean_mask = np.squeeze(boolean_mask, axis=2)

    # ç°åœ¨ä½¿ç”¨2Dæ©ç ä¸º3Då›¾åƒçš„åƒç´ èµ‹å€¼
    overlay_color[boolean_mask] = (0, 255, 0)  # BGR: Green

    result = cv2.addWeighted(color_arr, 1.0, overlay_color, 0.8, 0)

    # ä¸ºäº†å¯¹æ¯”ï¼Œæ˜¾ç¤ºæ˜ å°„åçš„åŸå§‹æ·±åº¦å›¾æ¸²æŸ“æ•ˆæœ
    img_registration_render = pcammls.image_data()
    mapped_depth_for_render = pcammls.image_data()
    cl.DeviceStreamMapDepthImageToColorCoordinate(
        depth_calib, img_depth, scale_unit, color_calib,
        img_color.width, img_color.height, mapped_depth_for_render
    )
    cl.DeviceStreamDepthRender(mapped_depth_for_render, img_registration_render)
    cv2.imshow("MappedDepthRender", img_registration_render.as_nparray())

    # æ˜¾ç¤ºæœ€ç»ˆçš„å åŠ ç»“æœ
    result = cv2.resize(result,(0,0),fx=0.5, fy=0.5)
    cv2.imshow("ColorSkeletonOverlay (Aligned)", result)


def extract_skeleton_from_surface_mask(surface_mask: np.ndarray, visualize: bool = True):
    """
    ç›´æ¥ä»è¡¨é¢æ©ç ï¼ˆå¦‚ Z å€¼æå–çš„æ©ç ï¼‰ä¸­æå–å†…å¤–è½®å»“å¹¶è®¡ç®—ä¸­è½´çº¿ï¼ˆéª¨æ¶ï¼‰ã€‚
    æ­¤å‡½æ•°ç»•è¿‡äº† RANSAC æ‹Ÿåˆï¼Œç›´æ¥å¤„ç†ç»™å®šçš„äºŒå€¼æ©ç ã€‚

    å‚æ•°:
        surface_mask: (H, W) çš„äºŒå€¼æ©ç  (uint8), 255 ä»£è¡¨ç›®æ ‡åŒºåŸŸã€‚
        visualize: æ˜¯å¦æ˜¾ç¤ºä¸­é—´è¿‡ç¨‹å’Œç»“æœçš„å¯è§†åŒ–çª—å£ã€‚

    è¿”å›:
        dilated_skeleton: (H, W, 3) çš„ BGR å›¾åƒï¼ŒåŒ…å«è†¨èƒ€åçš„éª¨æ¶çº¿ã€‚
                         å¦‚æœæ— æ³•ç”Ÿæˆï¼Œåˆ™è¿”å› Noneã€‚
    ä¿®æ”¹æ—¶é—´:  2025-06-25 17:19

    """
    if surface_mask is None or np.count_nonzero(surface_mask) == 0:
        print("è¾“å…¥çš„ surface_mask ä¸ºç©ºæˆ–ä¸åŒ…å«æœ‰æ•ˆåŒºåŸŸã€‚")
        return None

    # 1. ä»æ©ç ä¸­æå–å†…å¤–è½®å»“ï¼ˆé€šå¸¸æ˜¯é¢ç§¯æœ€å¤§çš„ä¸¤ä¸ªï¼‰

    contours = extract_contours_adaptive(surface_mask, min_vertices=4, max_vertices=16,initial_epsilon_factor=0.001)

    if len(contours) < 2:
        print("æœªèƒ½æ‰¾åˆ°è¶³å¤Ÿçš„å†…å¤–è½®å»“æ¥ç”Ÿæˆç¯çŠ¶åŒºåŸŸã€‚")
        return None

    outer_cnt = contours[0]
    inner_cnt = contours[1]

    # 2. åˆ›å»ºç¯çŠ¶åŒºåŸŸæ©è†œ (Ring Mask)
    ring_mask = np.zeros_like(surface_mask, dtype=np.uint8)
    cv2.drawContours(ring_mask, [outer_cnt], -1, 255, cv2.FILLED)  # å¡«å……å¤–è½®å»“
    cv2.drawContours(ring_mask, [inner_cnt], -1, 0, cv2.FILLED)   # åœ¨å†…è½®å»“åŒºåŸŸæŒ–ä¸€ä¸ªæ´

    # 3. æå–éª¨æ¶
    # ä½¿ç”¨ scikit-image çš„ skeletonize å‡½æ•°ï¼Œæ•ˆæœè¾ƒå¥½
    from skimage.morphology import skeletonize
    skeleton = skeletonize(ring_mask > 0)
    skeleton_img = (skeleton * 255).astype(np.uint8)

    # 4. è†¨èƒ€éª¨æ¶ä½¿å…¶æ›´ç²—ï¼Œä¾¿äºè§‚å¯Ÿå’Œåç»­å¤„ç†
    kernel = np.ones((1, 1), np.uint8)
    dilated_skeleton = cv2.dilate(skeleton_img, kernel, iterations=1)

    # 5. å¯è§†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if visualize:
        # åˆ›å»ºä¸€ä¸ªå½©è‰²å›¾åƒç”¨äºå¯è§†åŒ–
        vis_img = cv2.cvtColor(surface_mask, cv2.COLOR_GRAY2BGR)
        # ç»˜åˆ¶å†…å¤–è½®å»“
        cv2.drawContours(vis_img, [outer_cnt], -1, (0, 0, 255), 2)  # å¤–è½®å»“çº¢è‰²
        cv2.drawContours(vis_img, [inner_cnt], -1, (0, 255, 0), 2)  # å†…è½®å»“ç»¿è‰²
        # å°†éª¨æ¶å åŠ ä¸ºè“è‰²
        vis_img[dilated_skeleton != 0] = (255, 0, 0)

        cv2.imshow("Ring Mask", ring_mask)
        cv2.imshow("Skeleton from Surface Mask", vis_img)

    # è¿”å›ä¸€ä¸ªä¸‰é€šé“çš„å›¾åƒï¼Œæ–¹ä¾¿åç»­çš„é¢œè‰²å åŠ ç­‰æ“ä½œ
    return cv2.cvtColor(dilated_skeleton, cv2.COLOR_GRAY2BGR)


def extract_skeleton_universal(surface_mask: np.ndarray, visualize: bool = True):
    """
    é€šç”¨çš„éª¨æ¶æå–å‡½æ•°ï¼Œèƒ½åŒæ—¶å¤„ç†å®å¿ƒå’Œç©ºå¿ƒï¼ˆæœ‰é•‚ç©ºï¼‰çš„ç‰©ä½“ã€‚

    è¯¥å‡½æ•°é€šè¿‡æ£€æµ‹è½®å»“æ•°é‡æ¥è‡ªåŠ¨åˆ¤æ–­ç‰©ä½“ç±»å‹ï¼Œå¹¶ç›¸åº”åœ°åˆ›å»ºç”¨äºéª¨æ¶åŒ–çš„ç›®æ ‡æ©ç ã€‚
    - å¦‚æœåªæœ‰ä¸€ä¸ªè½®å»“ï¼Œåˆ™å¤„ç†ä¸ºå®å¿ƒç‰©ä½“ã€‚
    - å¦‚æœæœ‰å¤šä¸ªè½®å»“ï¼Œåˆ™å–æœ€å¤§çš„ä¸¤ä¸ªåˆ›å»ºç¯å½¢åŒºåŸŸè¿›è¡Œå¤„ç†ã€‚

    :param surface_mask: (H, W) çš„äºŒå€¼æ©ç  (uint8), 255 ä»£è¡¨ç›®æ ‡åŒºåŸŸã€‚
    :param visualize: æ˜¯å¦æ˜¾ç¤ºä¸­é—´è¿‡ç¨‹å’Œç»“æœçš„å¯è§†åŒ–çª—å£ã€‚
    :return: (H, W, 3) çš„ BGR å›¾åƒï¼ŒåŒ…å«è†¨èƒ€åçš„éª¨æ¶çº¿ã€‚å¦‚æœæ— æ³•ç”Ÿæˆï¼Œåˆ™è¿”å› Noneã€‚
    """
    if surface_mask is None or np.count_nonzero(surface_mask) == 0:
        print("è¾“å…¥çš„ surface_mask ä¸ºç©ºæˆ–ä¸åŒ…å«æœ‰æ•ˆåŒºåŸŸã€‚")
        return None

    # 1. æå–è½®å»“å¹¶è¿›è¡Œè‡ªé€‚åº”æ‹Ÿåˆ
    contours = extract_contours_adaptive(surface_mask, min_vertices=4, max_vertices=16, initial_epsilon_factor=0.001)

    if not contours:
        print("æœªèƒ½æ‰¾åˆ°ä»»ä½•è½®å»“ã€‚")
        return None

    # 2. â˜…â˜…â˜… æ ¸å¿ƒæ”¹åŠ¨ï¼šæ ¹æ®è½®å»“æ•°é‡å†³å®šå¤„ç†æ–¹å¼ â˜…â˜…â˜…
    target_mask = np.zeros_like(surface_mask, dtype=np.uint8)
    outer_cnt = contours[0]
    inner_cnt = None

    if len(contours) >= 2:
        # æƒ…å†µä¸€ï¼šç©ºå¿ƒç‰©ä½“ï¼ˆè‡³å°‘æœ‰ä¸¤ä¸ªè½®å»“ï¼‰
        print("æ£€æµ‹åˆ°ç©ºå¿ƒç‰©ä½“ï¼Œç”Ÿæˆç¯å½¢æ©ç ã€‚")
        inner_cnt = contours[1]
        # åˆ›å»ºç¯å½¢åŒºåŸŸ
        cv2.drawContours(target_mask, [outer_cnt], -1, 255, cv2.FILLED)
        cv2.drawContours(target_mask, [inner_cnt], -1, 0, cv2.FILLED)
    else:
        # æƒ…å†µäºŒï¼šå®å¿ƒç‰©ä½“ï¼ˆåªæœ‰ä¸€ä¸ªè½®å»“ï¼‰
        print("æ£€æµ‹åˆ°å®å¿ƒç‰©ä½“ï¼Œç”Ÿæˆå¡«å……æ©ç ã€‚")
        # åˆ›å»ºå®å¿ƒåŒºåŸŸ
        cv2.drawContours(target_mask, [outer_cnt], -1, 255, cv2.FILLED)

    # 3. æå–éª¨æ¶
    skeleton = skeletonize(target_mask > 0)
    skeleton_img = (skeleton * 255).astype(np.uint8)

    # 4. è†¨èƒ€éª¨æ¶ä½¿å…¶æ›´ç²—
    kernel = np.ones((3, 3), np.uint8)
    dilated_skeleton = cv2.dilate(skeleton_img, kernel, iterations=1)

    # 5. å¯è§†åŒ–
    if visualize:
        vis_img = cv2.cvtColor(surface_mask, cv2.COLOR_GRAY2BGR)
        cv2.drawContours(vis_img, [outer_cnt], -1, (0, 0, 255), 2)  # å¤–è½®å»“çº¢è‰²
        if inner_cnt is not None:
            cv2.drawContours(vis_img, [inner_cnt], -1, (0, 255, 0), 2)  # å†…è½®å»“ç»¿è‰²

        # å°†éª¨æ¶å åŠ ä¸ºè“è‰²
        vis_img[dilated_skeleton != 0] = (255, 0, 0)

        cv2.imshow("Target Mask for Skeletonization", target_mask)
        cv2.imshow("Universal Skeleton Extraction", vis_img)

    return cv2.cvtColor(dilated_skeleton, cv2.COLOR_GRAY2BGR)

def extract_skeleton_points_and_visualize(skeleton_image, origin_offset=(0, 0), visualize=True):
    """
    ä»éª¨æ¶å›¾ä¸­æå–æ‰€æœ‰ç¦»æ•£ç‚¹çš„åæ ‡ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°è¿›è¡Œå¯è§†åŒ–ã€‚
    è¯¥å‡½æ•°å¤„ç†åæ ‡ç³»è½¬æ¢ï¼Œå°†ROIå†…çš„å±€éƒ¨åæ ‡æ˜ å°„ä¸ºå…¨å±€åæ ‡ã€‚

    :param skeleton_image: è¾“å…¥çš„éª¨æ¶äºŒå€¼å›¾ (H, W) æˆ– (H, W, 3)ã€‚é€šå¸¸æ˜¯ extract_skeleton_* å‡½æ•°çš„è¾“å‡ºã€‚
    :param origin_offset: (x, y) æ ¼å¼çš„åç§»é‡ï¼Œå³ROIåœ¨åŸå›¾ä¸­çš„å·¦ä¸Šè§’åæ ‡ã€‚
    :param visualize: æ˜¯å¦åˆ›å»ºä¸€ä¸ªæ–°çª—å£æ¥ç»˜åˆ¶å¹¶æ˜¾ç¤ºè¿™äº›ç¦»æ•£ç‚¹ã€‚
    :return: ä¸€ä¸ª (N, 2) çš„ NumPy æ•°ç»„ï¼ŒåŒ…å«æ‰€æœ‰éª¨æ¶ç‚¹çš„ (x, y) å…¨å±€åæ ‡ã€‚å¦‚æœæ— æœ‰æ•ˆç‚¹åˆ™è¿”å›ç©ºæ•°ç»„ã€‚
    """
    # 1. ç¡®ä¿è¾“å…¥æ˜¯ 2D ç°åº¦å›¾
    if skeleton_image is None or skeleton_image.size == 0:
        print("è¾“å…¥çš„éª¨æ¶å›¾ä¸ºç©ºï¼Œæ— æ³•æå–ç‚¹ã€‚")
        return np.array([])

    if skeleton_image.ndim == 3:
        gray_skeleton = cv2.cvtColor(skeleton_image, cv2.COLOR_BGR2GRAY)
    else:
        gray_skeleton = skeleton_image

    # 2. æå–æ‰€æœ‰éé›¶åƒç´ çš„åæ ‡ (y, x)
    rows, cols = np.where(gray_skeleton > 0)

    if len(rows) == 0:
        print("éª¨æ¶å›¾ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆç‚¹ã€‚")
        return np.array([])

    # 3. å°†åæ ‡è½¬æ¢ä¸º (x, y) æ ¼å¼å¹¶åº”ç”¨å…¨å±€åç§»é‡
    # np.vstack((cols, rows)).T å°† (y,x) åæ ‡å¯¹è½¬æ¢ä¸º (N, 2) çš„ [x, y] æ ¼å¼æ•°ç»„
    local_points = np.vstack((cols, rows)).T
    global_points = local_points + np.array(origin_offset)

    # 4. åœ¨æ–°çª—å£ä¸­å¯è§†åŒ–ç¦»æ•£ç‚¹
    if visualize:
        # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥éª¨æ¶å›¾åŒæ ·å¤§å°çš„é»‘è‰²ç”»å¸ƒ
        vis_canvas = np.zeros((skeleton_image.shape[0], skeleton_image.shape[1], 3), dtype=np.uint8)

        # åœ¨ç”»å¸ƒä¸Šç»˜åˆ¶æ¯ä¸ªç¦»æ•£ç‚¹ï¼ˆä½¿ç”¨å±€éƒ¨åæ ‡ï¼‰
        for point in local_points:
            # point æ˜¯ [x, y] æ ¼å¼
            cv2.circle(vis_canvas, tuple(point), radius=1, color=(0, 255, 255), thickness=-1)  # ç»˜åˆ¶é»„è‰²çš„ç‚¹

        cv2.imshow("Discrete Skeleton Points (in ROI)", vis_canvas)

    return global_points


def compare_centerlines(actual_points, theoretical_points, image_shape):
    """
    æ¯”è¾ƒå®é™…ä¸­è½´çº¿å’Œç†è®ºä¸­è½´çº¿ï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–ç»“æœã€‚

    :param actual_points: (N, 2) numpyæ•°ç»„ï¼Œå®é™…ä¸­è½´çº¿åæ ‡ã€‚
    :param theoretical_points: (M, 2) numpyæ•°ç»„ï¼Œç†è®ºä¸­è½´çº¿åæ ‡ã€‚
    :param image_shape: (height, width) çš„å…ƒç»„ï¼Œç”¨äºåˆ›å»ºå¯è§†åŒ–å›¾åƒã€‚
    :return:
        - vis_image: (H, W, 3) BGRå›¾åƒï¼Œå¯è§†åŒ–æ¯”è¾ƒç»“æœã€‚
        - match_score: 0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºåŒ¹é…ç¨‹åº¦ã€‚
    """
    if actual_points.size == 0 or theoretical_points.size == 0:
        return np.zeros((image_shape[0], image_shape[1], 3), dtype=np.uint8), 0.0

    vis_image = np.zeros((image_shape[0], image_shape[1], 3), dtype=np.uint8)

    # ç»˜åˆ¶ç†è®ºä¸­è½´çº¿ (ç»¿è‰²)
    for i in range(len(theoretical_points) - 1):
        p1 = tuple(theoretical_points[i].astype(int))
        p2 = tuple(theoretical_points[i+1].astype(int))
        cv2.line(vis_image, p1, p2, (0, 255, 0), 2)

    # ç»˜åˆ¶å®é™…ä¸­è½´çº¿ (çº¢è‰²)
    for point in actual_points:
        cv2.circle(vis_image, tuple(point.astype(int)), radius=2, color=(0, 0, 255), thickness=-1)

    # è®¡ç®—åŒ¹é…ç¨‹åº¦
    tree = cKDTree(theoretical_points)
    distances, _ = tree.query(actual_points, k=1)

    # å°†è·ç¦»è¶…è¿‡ä¸€å®šé˜ˆå€¼ï¼ˆä¾‹å¦‚5ä¸ªåƒç´ ï¼‰çš„ç‚¹è§†ä¸ºä¸åŒ¹é…
    threshold = 5.0
    matched_points = np.sum(distances < threshold)
    match_score = matched_points / len(actual_points) if len(actual_points) > 0 else 0.0

    # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºåŒ¹é…åˆ†æ•°
    cv2.putText(vis_image, f"Match Score: {match_score*100:.2f}%", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    return vis_image, match_score

def calculate_deviation_vectors(actual_points, theoretical_points, num_key_points=10):
    """
    è®¡ç®—å®é™…ä¸­è½´çº¿ç›¸å¯¹äºç†è®ºä¸­è½´çº¿çš„åç§»å‘é‡ã€‚

    è¯¥å‡½æ•°åœ¨ç†è®ºä¸­è½´çº¿ä¸Šé€‰å–è‹¥å¹²å…³é”®ç‚¹ï¼Œç„¶åä¸ºæ¯ä¸ªå…³é”®ç‚¹æ‰¾åˆ°
    å®é™…ä¸­è½´çº¿ä¸Šæœ€è¿‘çš„å¯¹åº”ç‚¹ï¼Œå¹¶è®¡ç®—ä¸¤è€…ä¹‹é—´çš„åç§»å‘é‡ã€‚

    :param actual_points: (N, 2) numpyæ•°ç»„ï¼Œå®é™…ä¸­è½´çº¿åæ ‡ã€‚
    :param theoretical_points: (M, 2) numpyæ•°ç»„ï¼Œç†è®ºä¸­è½´çº¿åæ ‡ã€‚
    :param num_key_points: è¦åœ¨ç†è®ºä¸­è½´çº¿ä¸Šé€‰å–çš„å…³é”®ç‚¹æ•°é‡ã€‚
    :return: ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ (key_point, deviation_vector)ï¼Œ
             å…¶ä¸­ key_point æ˜¯ç†è®ºå…³é”®ç‚¹çš„åæ ‡ï¼Œdeviation_vector æ˜¯ (dx, dy) å½¢å¼çš„åç§»å‘é‡ã€‚
             å¦‚æœè¾“å…¥ä¸ºç©ºï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    if actual_points.size == 0 or theoretical_points.size == 0:
        return []

    # 1. åœ¨ç†è®ºä¸­è½´çº¿ä¸Šå‡åŒ€é€‰å–å…³é”®ç‚¹
    key_point_indices = np.linspace(0, len(theoretical_points) - 1, num_key_points, dtype=int)
    theory_key_points = theoretical_points[key_point_indices]

    # 2. æ„å»ºå®é™…ä¸­è½´çº¿ç‚¹çš„ KDTree ä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾æœ€è¿‘é‚»
    tree = cKDTree(actual_points)

    deviation_results = []
    # 3. ä¸ºæ¯ä¸ªç†è®ºå…³é”®ç‚¹æ‰¾åˆ°å®é™…å¯¹åº”ç‚¹å¹¶è®¡ç®—å‘é‡
    for key_point in theory_key_points:
        # æŸ¥æ‰¾æœ€è¿‘çš„å®é™…ç‚¹
        distance, nearest_index = tree.query(key_point)
        actual_corresponding_point = actual_points[nearest_index]

        # è®¡ç®—åç§»å‘é‡
        deviation_vector = actual_corresponding_point - key_point
        deviation_results.append((key_point, deviation_vector))

    return deviation_results

def visualize_deviation_vectors(vis_image, deviation_results):
    """
    åœ¨å›¾åƒä¸Šå°†åç§»å‘é‡å¯è§†åŒ–ä¸ºç®­å¤´ã€‚

    :param vis_image: è¦ç»˜åˆ¶çš„ BGR å›¾åƒã€‚
    :param deviation_results: calculate_deviation_vectors å‡½æ•°çš„è¾“å‡ºç»“æœã€‚
    :return: ç»˜åˆ¶äº†å‘é‡åçš„å›¾åƒã€‚
    """
    img_with_vectors = vis_image.copy()
    for key_point, vector in deviation_results:
        start_point = tuple(key_point.astype(int))
        end_point = tuple((key_point + vector).astype(int))

        # ç»˜åˆ¶ä»å®é™…ç‚¹æŒ‡å‘ç†è®ºç‚¹çš„ç®­å¤´ï¼Œè¡¨ç¤ºåå·®æ–¹å‘

        cv2.arrowedLine(img_with_vectors, end_point, start_point, (0, 255, 255), 2, tipLength=0.4) # é»„è‰²ç®­å¤´
        # æ ‡è®°ç†è®ºå…³é”®ç‚¹ä½ç½®
        cv2.circle(img_with_vectors, start_point, radius=3, color=(255, 0, 0), thickness=-1) # è“è‰²åœ†ç‚¹

    return img_with_vectors

def visualize_z_channel(p3d_array, window_name="Z-Channel Visualization"):
    """
    å°†ç‚¹äº‘çš„ Z é€šé“å¯è§†åŒ–ä¸ºä¸€å¼ ä¼ªå½©è‰²æ·±åº¦å›¾ã€‚

    :param p3d_array: (H, W, 3) çš„ç‚¹äº‘ NumPy æ•°ç»„ã€‚
    :param window_name: æ˜¾ç¤ºçª—å£çš„åç§°ã€‚
    """
    # 1. æå– Z é€šé“
    z_channel = p3d_array[:, :, 2].copy()

    # 2. æ‰¾åˆ°æœ‰æ•ˆçš„ Z å€¼ (éæ— ç©·å¤§æˆ– NaN)
    valid_mask = np.isfinite(z_channel) & (z_channel != 0)
    if not np.any(valid_mask):
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œæ˜¾ç¤ºä¸€å¼ é»‘å›¾
        cv2.imshow(window_name, np.zeros((z_channel.shape[0], z_channel.shape[1], 3), dtype=np.uint8))
        return

    # 3. å°†æœ‰æ•ˆ Z å€¼å½’ä¸€åŒ–åˆ° 0-255 èŒƒå›´ä»¥ä¾¿æ˜¾ç¤º
    z_valid = z_channel[valid_mask]
    z_min, z_max = np.min(z_valid), np.max(z_valid)

    if z_max - z_min > 0:
        # å½’ä¸€åŒ–
        normalized_z = (z_channel - z_min) / (z_max - z_min) * 255
    else:
        # å¦‚æœæ‰€æœ‰å€¼éƒ½ä¸€æ ·ï¼Œåˆ™è®¾ä¸ºä¸­é—´å€¼
        normalized_z = np.full(z_channel.shape, 128)

    # å°†å½’ä¸€åŒ–åçš„å€¼è½¬æ¢ä¸º 8 ä½æ— ç¬¦å·æ•´æ•°
    z_uint8 = normalized_z.astype(np.uint8)

    # 4. åº”ç”¨ä¼ªå½©è‰²æ˜ å°„è¡¨ä»¥å¢å¼ºå¯è§†åŒ–æ•ˆæœ
    colored_z = cv2.applyColorMap(z_uint8, cv2.COLORMAP_JET)

    # åœ¨æ— æ•ˆåŒºåŸŸæ˜¾ç¤ºä¸ºé»‘è‰²
    colored_z[~valid_mask] = [0, 0, 0]

    # 5. æ˜¾ç¤ºå›¾åƒ
    cv2.imshow(window_name, colored_z)

def main():
    cl = PercipioSDK()

    dev_list = cl.ListDevice()
    for idx in range(len(dev_list)):
        dev = dev_list[idx]
        print('{} -- {} \t {}'.format(idx, dev.id, dev.iface.id))
    if len(dev_list) == 0:
        print('no device')
        return
    if len(dev_list) == 1:
        selected_idx = 0
    else:
        selected_idx = int(input('select a device:'))
    if selected_idx < 0 or selected_idx >= len(dev_list):
        return

    sn = dev_list[selected_idx].id

    # åŠ è½½ç†è®ºä¸­è½´çº¿
    try:
        theoretical_centerline = np.load('theoretical_centerline.npy')
    except FileNotFoundError:
        print("è­¦å‘Š: æœªæ‰¾åˆ° 'theoretical_centerline.npy'ã€‚è¯·å…ˆè¿è¡Œ draw_centerline.py åˆ›å»ºç†è®ºä¸­è½´çº¿ã€‚")
        theoretical_centerline = None
    try:
        rotation_matrix = np.load('tilt_correction_matrix.npy')
        print("æˆåŠŸåŠ è½½å€¾æ–œæ ¡æ­£çŸ©é˜µã€‚")
    except FileNotFoundError:
        rotation_matrix = None
        print("è­¦å‘Š: æœªæ‰¾åˆ° 'tilt_correction_matrix.npy'ã€‚")
        print("ç¨‹åºå°†ä¸è¿›è¡Œå€¾æ–œæ ¡æ­£ã€‚è¯·å…ˆè¿è¡Œ my_calibrate.py è¿›è¡Œæ ¡å‡†ã€‚")
    try:
        hand_eye_matrix = np.load('hand_eye_transform.npy')
        print("æˆåŠŸåŠ è½½æ‰‹çœ¼æ ‡å®šçŸ©é˜µ 'hand_eye_transform.npy'ã€‚")
    except FileNotFoundError:
        print("è­¦å‘Š: æœªæ‰¾åˆ°æ‰‹çœ¼æ ‡å®šçŸ©é˜µ 'hand_eye_transform.npy'ã€‚")
        print("å°†æ— æ³•è®¡ç®—ç‰©ç†åç§»é‡ã€‚è¯·å…ˆè¿è¡Œ calibrate_hand_eye.pyã€‚")
        hand_eye_matrix = None

    handle = cl.Open(sn)
    if not cl.isValidHandle(handle):
        err = cl.TYGetLastErrorCodedescription()
        print('no device found : ', end='')
        print(err)
        return

    event = PythonPercipioDeviceEvent()
    cl.DeviceRegiststerCallBackEvent(event)

    ## START
    color_fmt_list = cl.DeviceStreamFormatDump(handle, PERCIPIO_STREAM_COLOR)
    if len(color_fmt_list) == 0:
        print('device has no color stream.')
        return

    print('color image format list:')
    for idx in range(len(color_fmt_list)):
        fmt = color_fmt_list[idx]
        print('\t{} -size[{}x{}]\t-\t desc:{}'.format(idx, cl.Width(fmt), cl.Height(fmt), fmt.getDesc()))
    cl.DeviceStreamFormatConfig(handle, PERCIPIO_STREAM_COLOR, color_fmt_list[0])

    depth_fmt_list = cl.DeviceStreamFormatDump(handle, PERCIPIO_STREAM_DEPTH)
    if len(depth_fmt_list) == 0:
        print('device has no depth stream.')
        return

    print('depth image format list:')
    for idx in range(len(depth_fmt_list)):
        fmt = depth_fmt_list[idx]
        print('\t{} -size[{}x{}]\t-\t desc:{}'.format(idx, cl.Width(fmt), cl.Height(fmt), fmt.getDesc()))

    cl.DeviceStreamFormatConfig(handle, PERCIPIO_STREAM_DEPTH, depth_fmt_list[0])

    err = cl.DeviceLoadDefaultParameters(handle)
    if err:
        print('Load default parameters fail: ', end='')
        print(cl.TYGetLastErrorCodedescription())
    else:
        print('Load default parameters successful')

    # è¯»å–æ ¡å‡†æ•°æ®
    scale_unit = cl.DeviceReadCalibDepthScaleUnit(handle)
    print('depth image scale unit :{}'.format(scale_unit))  # 0.125
    depth_calib = cl.DeviceReadCalibData(handle, PERCIPIO_STREAM_DEPTH)
    color_calib = cl.DeviceReadCalibData(handle, PERCIPIO_STREAM_COLOR)
    depth_calib_data = cl.DeviceReadCalibData(handle, PERCIPIO_STREAM_DEPTH)
    depth_calib_width = depth_calib_data.Width()
    depth_calib_height = depth_calib_data.Height()
    depth_calib_intr = depth_calib_data.Intrinsic()
    depth_calib_extr = depth_calib_data.Extrinsic()
    depth_calib_dis = depth_calib_data.Distortion()

    err = cl.DeviceStreamEnable(handle, PERCIPIO_STREAM_COLOR | PERCIPIO_STREAM_DEPTH)
    if err:
        print('device stream enable err:{}'.format(err))
        return

    print('{} -- {} \t'.format(0, "Map depth to color coordinate(suggest)"))
    print('{} -- {} \t'.format(1, "Map color to depth coordinate"))
    # æ¨¡å¼0ï¼šå°†æ·±åº¦å›¾æ˜ å°„åˆ°å½©è‰²å›¾åæ ‡ç³»ï¼ˆå¸¸ç”¨ï¼Œå½©è‰²å›¾åˆ†è¾¨ç‡é€šå¸¸æ›´é«˜ï¼‰ã€‚
    # æ¨¡å¼1ï¼šå°†å½©è‰²å›¾æ˜ å°„åˆ°æ·±åº¦å›¾åæ ‡ç³»ã€‚
    # registration_mode = int(input('select registration mode(0 or 1):'))
    # if selected_idx < 0 or selected_idx >= 2:
    #     registration_mode = 0
    registration_mode = 2

    cl.DeviceStreamOn(handle)

    # ç‚¹äº‘æ•°æ®
    pointcloud_data_arr = pointcloud_data_list()

    img_registration_depth = image_data()
    img_registration_render = image_data()
    img_parsed_color = image_data()
    img_undistortion_color = image_data()
    img_registration_color = image_data()

    count = 0

    # æ·±åº¦å›¾åˆ†è¾¨ç‡ï¼š(1920, 2560)
    # ç‚¹äº‘å›¾åˆ†è¾¨ç‡ï¼š(1536, 2048ï¼‰
    ROI_X1, ROI_Y1 = 900, 800  # å·¦ä¸Šè§’åæ ‡
    ROI_X2, ROI_Y2 = 1600, 1400  # å³ä¸‹è§’åæ ‡

    while True:
        if event.IsOffline():
            break
        image_list = cl.DeviceStreamRead(handle, 2000)
        if len(image_list) == 2:
            frame = []
            for i in range(len(image_list)):
                frame = image_list[i]
                if frame.streamID == PERCIPIO_STREAM_DEPTH:
                    img_depth = frame
                if frame.streamID == PERCIPIO_STREAM_COLOR:
                    img_color = frame

            if registration_mode == 2:  # å½©è‰²ç‚¹äº‘æ˜¾ç¤º

                # ROI_X1, ROI_Y1 = 800, 700  # å·¦ä¸Šè§’åæ ‡
                # ROI_X2, ROI_Y2 = 1200, 1050  # å³ä¸‹è§’åæ ‡
                # è¿™é‡Œä½¿ç”¨çš„æ˜¯æ·±åº¦å›¾åˆ†è¾¨ç‡çš„ ROI
                # æ­£æ–¹å½¢çš„
                ROI_X1, ROI_Y1 = 993, 614  # å·¦ä¸Šè§’åæ ‡
                ROI_X2, ROI_Y2 = 1186, 790  # å³ä¸‹è§’åæ ‡
                #backup
                # ROI_X1, ROI_Y1 = 915, 709  # å·¦ä¸Šè§’åæ ‡
                # ROI_X2, ROI_Y2 = 980, 790  # å³ä¸‹è§’åæ ‡


                # ç‚¹äº‘è½¬æ¢
                cl.DeviceStreamMapDepthImageToPoint3D(frame, depth_calib_data, scale_unit, pointcloud_data_arr)
                sz = pointcloud_data_arr.size()
                print('get p3d size : {}'.format(sz))  # get p3d size : 3145728
                p3d_nparray = pointcloud_data_arr.as_nparray()  # (1536, 2048, 3)
                visualize_z_channel(p3d_nparray, "Z-Channel (Before Correction)")
                # ç‚¹äº‘æ ¡å‡†
                if rotation_matrix is not None:
                    # è·å–ç‚¹äº‘çš„åŸå§‹å½¢çŠ¶
                    original_shape = p3d_nparray.shape
                    # å°†ç‚¹äº‘æ•°æ®ä» (H, W, 3) å˜å½¢ä¸º (N, 3) ä»¥ä¾¿è¿›è¡ŒçŸ©é˜µä¹˜æ³•
                    points = p3d_nparray.reshape(-1, 3)

                    # è¿‡æ»¤æ‰æ— æ•ˆç‚¹ (z<=0)ï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—
                    valid_points_mask = points[:, 2] > 0

                    # ä½¿ç”¨çŸ©é˜µè¿›è¡Œæ—‹è½¬ï¼šp' = R * p^T  (è¿™é‡Œç”¨ p @ R.T æ›´é«˜æ•ˆ)
                    # åªå¯¹æœ‰æ•ˆç‚¹è¿›è¡Œæ—‹è½¬
                    points[valid_points_mask] = points[valid_points_mask] @ rotation_matrix.T

                    # å°†æ—‹è½¬åçš„ç‚¹äº‘æ•°æ®æ¢å¤ä¸ºåŸå§‹çš„ (H, W, 3) å½¢çŠ¶
                    p3d_nparray = points.reshape(original_shape)
                    print("å·²å¯¹ç‚¹äº‘åº”ç”¨å€¾æ–œæ ¡æ­£ã€‚")
                    visualize_z_channel(p3d_nparray, "Z-Channel (After Correction)")

                # æ·±åº¦å›¾æ˜¾ç¤º
                cl.DeviceStreamDepthRender(frame, img_registration_depth)
                depth = img_registration_depth.as_nparray()

                # æå–ç‚¹äº‘ ROI
                roi_cloud = p3d_nparray[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2]
                cv2.imshow("roi_p3d_nparray", roi_cloud)


                if rotation_matrix is None:
                    print("æœªè¿›è¡Œå€¾æ–œæ ¡æ­£ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•æå–æ©ç ã€‚")
                    surface_mask, z_min = extract_nearest_surface_mask(roi_cloud, depth_margin=3.5)
                else:
                    # å¦‚æœå·²æ ¡æ­£ï¼Œåˆ™ä½¿ç”¨æ­£äº¤æŠ•å½±ç”Ÿæˆæ— ç•¸å˜æ©ç 
                    print("å·²è¿›è¡Œå€¾æ–œæ ¡æ­£ï¼Œä½¿ç”¨æ­£äº¤æŠ•å½±ç”Ÿæˆæ— ç•¸å˜æ©ç ã€‚")
                    # surface_mask, z_min = create_corrected_mask(roi_cloud, depth_margin=5.5, pixel_size_mm= 0.5)
                    # ä½¿ç”¨åŸå§‹æ–¹å¼ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†ç©ºå¿ƒç‰©ä½“
                    # surface_mask, z_min = extract_nearest_surface_mask(roi_cloud, depth_margin=5.8)
                    # ä½¿ç”¨ RANSAC æ–¹æ³•æå–è¡¨é¢æ©ç ï¼Œé€‚åº”ç²—ç³™è¡¨é¢
                    surface_mask, z_min = extract_nearest_surface_mask_ransac(roi_cloud, depth_margin=3.8, ransac_iters=400,
                                                        dist_thresh=0.8,front_percentile=20.0,subsample=50000,random_state=1)
                if surface_mask is None:
                    print("æ— æ³•æå–è¡¨é¢æ©ç ï¼Œè·³è¿‡æ­¤å¸§ã€‚")
                    continue
                cv2.imshow("Initial Surface Mask", surface_mask)

                # # ç›´æ¥ä» surface_mask è®¡ç®—ä¸­è½´çº¿ï¼Œä¸å†ä½¿ç”¨ RANSAC
                # dilation_vis = extract_skeleton_from_surface_mask(surface_mask, visualize=True)
                # # ä½¿ç”¨é€šç”¨éª¨æ¶æå–æ–¹æ³•ï¼Œèƒ½å¤„ç†å®å¿ƒå’Œç©ºå¿ƒç‰©ä½“
                dilation_vis = extract_skeleton_universal(surface_mask, visualize=True)

                # # ä½¿ç”¨RANSACæ‹Ÿåˆå¹³é¢å¹¶æå–é«˜åº¦å›¾ï¼Œé²æ£’æ€§é«˜ï¼Œä½†å‡†ç¡®åº¦å¯èƒ½ä¸å¦‚ç›´æ¥æå–æœ€è¿‘ä¸€å±‚ç‚¹äº‘åŒºåŸŸã€‚
                # # plane_model, inlier_mask, height_map, conter_vis = fit_plane_and_extract_height_map(
                # #     roi_cloud,
                # #     distance_threshold=4.8,
                # #     visualize=True,
                # # )

                if dilation_vis is not None:

                    # æå–ä¸­è½´çº¿çš„ç¦»æ•£ç‚¹ï¼Œå¹¶ä¼ å…¥ROIçš„åç§»é‡(ROI_X1, ROI_Y1)æ¥è·å–å…¨å±€åæ ‡
                    skeleton_points = extract_skeleton_points_and_visualize(
                        dilation_vis,
                        origin_offset=(ROI_X1, ROI_Y1),
                        visualize=True
                    )

                    # æ‰“å°è¿”å›çš„æ•°æ®ï¼Œä¾›åç»­æ¯”è¾ƒå’Œåˆ†æ
                    print(f"æå–åˆ° {len(skeleton_points)} ä¸ªä¸­è½´çº¿ç¦»æ•£ç‚¹ã€‚")
                    if len(skeleton_points) > 5:
                        print("å‰5ä¸ªç‚¹çš„å…¨å±€åæ ‡ (x, y):")
                        print(skeleton_points[:5])


                    # --- æ¯”è¾ƒä¸­è½´çº¿å¹¶è®¡ç®—å’Œæ˜¾ç¤ºåç§»å‘é‡ ---
                    if theoretical_centerline is not None:
                        # æ­¥éª¤ 1: ç”ŸæˆåŸºç¡€çš„å¯¹æ¯”å›¾
                        comparison_vis, match_score = compare_centerlines(
                            skeleton_points,
                            theoretical_centerline,
                            (depth.shape[0], depth.shape[1])
                        )
                        print(f"ä¸­è½´çº¿åŒ¹é…åº¦: {match_score:.2f}")

                        # æ­¥éª¤ 2: è®¡ç®—åç§»å‘é‡
                        deviation_vectors = calculate_deviation_vectors(
                            skeleton_points,
                            theoretical_centerline,
                            num_key_points=12
                        )

                        # æ‰“å°è¾“å‡ºçº åæ•°æ®
                        print("--- å…³é”®ç‚¹åç§»å‘é‡ (ç†è®ºç‚¹ -> å®é™…ç‚¹) ---")
                        for i, (key_pt, vec) in enumerate(deviation_vectors):
                            print(f"  å…³é”®ç‚¹ {i}: ç†è®ºä½ç½® {key_pt.astype(int)}, åç§» (dx, dy) = {vec.astype(int)}")

                        # è®¡ç®—å¹¶è¾“å‡ºå¹³å‡åç§»é‡
                        if deviation_vectors:
                            # æå–æ‰€æœ‰çš„åç§»å‘é‡ (dx, dy)
                            all_vectors = np.array([vec for _, vec in deviation_vectors])
                            # è®¡ç®—å¹³å‡åç§»é‡
                            average_offset = np.mean(all_vectors, axis=0)
                            print("--- å¹³å‡åç§»é‡ (dx, dy) ---")
                            print(f"  ({average_offset[0]:.2f}, {average_offset[1]:.2f})")

                            if hand_eye_matrix is not None:
                                # æå–çŸ©é˜µçš„çº¿æ€§éƒ¨åˆ† (æ—‹è½¬å’Œç¼©æ”¾)
                                linear_transform = hand_eye_matrix[:, :2]

                                # è®¡ç®—ç‰©ç†ä¸–ç•Œä¸­çš„åç§»é‡ (dX, dY)
                                physical_offset = linear_transform @ average_offset

                                print("--- çº æ­£åçš„å¹³å‡ç‰©ç†åç§»é‡ (dX, dY) ---")
                                print(f"  ({physical_offset[0]:.3f}, {physical_offset[1]:.3f}) mm")

                        # æ­¥éª¤ 3: åœ¨å¯¹æ¯”å›¾ä¸Šå¯è§†åŒ–åç§»å‘é‡
                        final_vis = visualize_deviation_vectors(comparison_vis, deviation_vectors)
                        # # çª—å£å¤§å°è°ƒæ•´æˆä¸€åŠ
                        # final_vis = cv2.resize(final_vis, (0, 0), fx=0.5, fy=0.5)

                        cv2.imshow("Centerline Comparison with Deviation Vectors", final_vis)

                    # --- ç»“æŸæ–°å¢ ---

                    if dilation_vis.ndim == 3 and dilation_vis.shape[2] == 3:
                        if np.array_equal(dilation_vis[:, :, 0], dilation_vis[:, :, 1]) and \
                                np.array_equal(dilation_vis[:, :, 0], dilation_vis[:, :, 2]):
                            dilation_vis = dilation_vis[:, :, 0].copy()
                        else:
                            dilation_vis = cv2.cvtColor(dilation_vis, cv2.COLOR_BGR2GRAY)

                    # åˆ›å»ºä¸å®Œæ•´æ·±åº¦å›¾åŒæ ·å¤§å°çš„æ©ç 
                    full_mask = np.zeros((depth.shape[0], depth.shape[1]), dtype=dilation_vis.dtype)
                    # å°†ROIåŒºåŸŸçš„éª¨æ¶å¡«å……åˆ°æ­£ç¡®ä½ç½®
                    full_mask[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2] = dilation_vis
                    cv2.imshow("full_mask", full_mask)

                    # åœ¨æ·±åº¦å›¾ä¸Šå åŠ éª¨æ¶
                    mask_color = np.zeros_like(depth)
                    mask_color[full_mask == 255] = (102, 255, 255)  # æµ…ç»¿è‰²
                    overlay = cv2.addWeighted(depth, 0.6, mask_color, 0.4, 0)
                    # draw
                    cv2.rectangle(overlay, (ROI_X1, ROI_Y1), (ROI_X2, ROI_Y2), (255, 0, 0), 2)
                    cv2.imshow("result", overlay)

                    original_color = image_data()
                    cl.DeviceStreamImageDecode(img_color,original_color)
                    color_arr = original_color.as_nparray()
                    cv2.imshow("original_color_arr", color_arr)
                    # åœ¨å½©è‰²å›¾ä¸Šå åŠ éª¨æ¶çº¿
                    overlay_skeleton_with_scaling(
                        cl, depth_calib, img_depth, scale_unit,
                        color_calib, img_color, full_mask
                    )

            k = cv2.waitKey(10)
            if k == ord('q'):
                break

    cl.DeviceStreamOff(handle)
    cl.Close(handle)
    cv2.destroyAllWindows()


if __name__ == '__main__':
    main()
